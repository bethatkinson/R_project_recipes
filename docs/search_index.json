[
["index.html", "R Recipes for Common Medical Projects", " R Recipes for Common Medical Projects "],
["preface.html", "Preface 0.1 Getting Started 0.2 R markdown 0.3 The Data 0.4 Scenarios 0.5 Finding help 0.6 Disclosure 0.7 Contributors", " Preface This book contains R recipes for typical analyses done for medical research projects. The objectives of this book: Create Mock projects and analyze the data using R Give people code snippets that they can use for their own projects Show how the various packages and functions fit together Recommend key packages for summarizing data Provide links for further study Model best practices for coding Encourage the use of RStudio and R markdown The assumption is that users will have some basic knowledge of R. Instead of re-creating introductory information or extended lists of options, we have chosen to provide one way of doing the analysis (with a perhaps a few more at the end of each scenario). Links are provided to other resources for more education. 0.1 Getting Started Although not required, we strongly encourage that users work through these examples using RStudio. RStudio is an integrated environment that includes an editor to write code, a console to execute code, a workspace to view objects in your session, a help window, and much more. Information on using RStudio can be found at https://moderndive.netlify.com/1-getting-started.html. Most of the functions used in this book are from base R or tidyverse packages (other packages will be described, when used, throughout this book). Direct links to packages used for each scenario are included at the end of the scenarios. Tidyverse is a collection of packages designed to work together to solve data science problems. The figure below includes the stages of an analysis and the tidyverse packages developed for each stage. Core tidyverse packages can be loaded into your R session with library(tidyverse). The function tidyverse_packages() details what packages are in the tidyverse while the search() command shows what packages have been loaded. There are additional packages that are considered a part of the tidyverse that are not automatically loaded. Highlights of some of the key tidyverse packages are shown in the appendix. &gt; library(tidyverse) # load basic tidyverse packages &gt; search() # see what was loaded [1] &quot;.GlobalEnv&quot; &quot;package:forcats&quot; &quot;package:stringr&quot; [4] &quot;package:dplyr&quot; &quot;package:purrr&quot; &quot;package:readr&quot; [7] &quot;package:tidyr&quot; &quot;package:tibble&quot; &quot;package:ggplot2&quot; [10] &quot;package:tidyverse&quot; &quot;package:stats&quot; &quot;package:graphics&quot; [13] &quot;package:grDevices&quot; &quot;package:utils&quot; &quot;package:datasets&quot; [16] &quot;package:methods&quot; &quot;Autoloads&quot; &quot;package:base&quot; &gt; &gt; tidyverse_packages(include_self = TRUE) # list all packages in tidyverse [1] &quot;broom&quot; &quot;cli&quot; &quot;crayon&quot; &quot;dbplyr&quot; &quot;dplyr&quot; [6] &quot;forcats&quot; &quot;ggplot2&quot; &quot;haven&quot; &quot;hms&quot; &quot;httr&quot; [11] &quot;jsonlite&quot; &quot;lubridate&quot; &quot;magrittr&quot; &quot;modelr&quot; &quot;pillar&quot; [16] &quot;purrr&quot; &quot;readr&quot; &quot;readxl&quot; &quot;reprex&quot; &quot;rlang&quot; [21] &quot;rstudioapi&quot; &quot;rvest&quot; &quot;stringr&quot; &quot;tibble&quot; &quot;tidyr&quot; [26] &quot;xml2&quot; &quot;tidyverse&quot; 0.2 R markdown R markdown (file extention .Rmd) is a simple way to integrate R output and text, then output as HTML, PDF, or Word. The syntax is pretty basic (e.g., a bulleted list is simply an astrix * followed by text). R markdown is much easier to compile and explore using RStudio, thought it can be run using R from a terminal window. There is a lot of documentation available on getting started with R Markdown including: RStudio cheatsheets RStudio webinar archives 0.3 The Data There are separate datasets used for each scenario. They are based on real data but certain variables are simulated or perturbed. Patient ID numbers have all been fabricated. You can try the exercises out by first downloading the data to your home directory or read in the data from the Github page using the provided code. The exercises assume that you have the files in a subdirectory called “data” that is in the same directory as your programs. 0.4 Scenarios Scenario 1: Getting Familiar with a New Project In this scenario, you are starting a new project and want to get familiar with the data. It covers: Import Data Explore Data + Identify and deal with strange values and duplicate observations + Generate summary statistics Plot Data Fit a simple model Scenario 2: Modeling and Plotting with Cleaned Data In this scenario, you already cleaned your data but want to do more complex models and plots. Deal with missing data Plot Kaplan Meier &amp; cumulative incidence curves Run linear, logistic &amp; Cox models Scenario 3: Working with Multiple Observations per Subject In this scenario you will work with multiple observations per subject as is often found in longitudinal data. Explore and clean baseline data Using a cleaned version of the full dataset (up to 4 visits per subject), transform the data from 1 obs/subject to 1 obs/subject/visit. Plot the data with separate lines for each subject Fit linear models and linear mixed effects models 0.5 Finding help There are several ways to find additional help. Using the help function. These are to remind the user of the argument names, but are not extensive. help(foo) # brief help/syntax about function foo ?foo # same thing example(foo) # show an example of function foo apropos(&quot;foo&quot;) # list all functions containing the string &quot;foo&quot; Vignettes. These generally provide more detailed examples if they are available. vignette() # show available vignettes in loaded packages vignette(&quot;foo&quot;) # show specific vignette Or search the web for “R vignette foo” Try one these sites Quick-R stack overflow Statistical tools for high-throughput data analysis (STHDA) Use package cheat sheets RStudio Online Learning Google tips Use key “R” words like ggplot: ggplot add horizontal line Check the date of the posting, especially for code relating to the tidyverse. It is still relatively new and the coding has changed over time. 0.6 Disclosure The solutions presented here are one way to do things (usually the “easy” way), and there was a lot of discussion about which was the “easy” way. Alternative solutions are presented in the appendix. 0.7 Contributors This series of examples was created by Beth Atkinson, Brendan Broderick, Erin Carlson, Krista Goergen, Mike Golafshar, Ethan Heinzen, Katie Kunze, Liz Lesser, Peter Martin, Ryan Lennon. "],
["scenario-1-getting-familiar-with-a-new-project.html", "1 Scenario 1: Getting Familiar with a New Project 1.1 Your Mission 1.2 Implementation 1.3 Resources 1.4 Optional ways to code", " 1 Scenario 1: Getting Familiar with a New Project You’re handed a new project to work on and the abstract deadline is next week. You need to get something out the door soon! 1.1 Your Mission Import Data Read in the example dataset dat1.sas7bdat. What variables are in the data? Are they character, numeric, Date, or factor? Explore Data Take a closer look at the data using basic summary statistics. Do you notice any strange values? If so, fix them. Are there any duplicate observations? If so, see whether you can delete any of them. Summarize age, gender, bmi, etc. by the treatment variable using parametric statistics. Do the summary statistics make sense for each variable? If not, modify the variables so that the default summaries are appropriate. Change the label for the variable age. Now change the table summary statistics to be non-parametric. How many people have the combinations of ps, sex, and treatment arm? Create a formula from a list of variables that can used in tableby (hint: try formulize) Plot Data Create a boxplot of bmi. Now create the boxplots stratified by the treatment arm. Modify the axis labels and add a title to your plot. Create a scatterplot of age versus another continuous variable. Now create the plot with separate colors for one of the group variables. Now make two scatterplots of age versus bmi with different colors indicating treatment. Create these same scatterplots, side-by-side, separately for males and females. How would you add a regression line to these plots? How about smoothers? Basic Modeling Run a simple linear regression model predicting bmi with a covariate that is coded as 1/2. Now re-do it with the covariate coded as a factor. Did the answer change? Data Import, revisited Read the data in from Excel and compare it with the version that came from SAS. What is different? 1.2 Implementation 1.2.1 Import Data Read in the example dataset dat1.sas7bdat. What variables are in the data? Are they character, numeric, Date, or factor? When reading in SAS data you can use the read_sas() function that is found in the haven package. To make a package available simply use the library() function with the non-quoted name of the package. The read_sas() function works for the majority of SAS datasets. Other options are found at the end of this document in the rare situations where you need to use a different tool. &gt; # Before doing any work, you are strongly encouraged to set this option in each &gt; # of your programs (default for later versions of R) &gt; options(stringsAsFactors = FALSE) &gt; &gt; # various functions from the tidyverse package are used. You can safely ignore &gt; # the messages regarding conflicts for now &gt; library(tidyverse) &gt; # use the read_sas function found in the haven package &gt; library(haven) &gt; # the knitr package includes the kable function for simple nice tables &gt; library(knitr) &gt; &gt; # link to data on GitHub page if not already downloaded &gt; if (!file.exists(&quot;data/dat1.sas7bdat&quot;)) { + urlfile &lt;- &quot;https://raw.githubusercontent.com/bethatkinson/R_project_recipes/data/dat1.sas7bdat&quot; + if (!dir.exists(&quot;data&quot;)) + dir.create(&quot;data&quot;) + download.file(urlfile, destfile = &quot;data/dat1.sas7bdat&quot;) + } &gt; &gt; dat1 &lt;- read_sas(&quot;data/dat1.sas7bdat&quot;) Once we successfully import data into the current R session we should explore it a little bit. The names() function is a good first step as it displays all the column names of the data, and you can quickly check to see if your import went as expected. names() returns a character vector &gt; names(dat1) [1] &quot;id&quot; &quot;age&quot; &quot;arm&quot; &quot;sex&quot; &quot;futime&quot; [6] &quot;fustat&quot; &quot;ps&quot; &quot;hgb&quot; &quot;bmi&quot; &quot;alkphos&quot; [11] &quot;ast&quot; &quot;mdqualitys&quot; &quot;ageord&quot; &quot;birthdt&quot; &quot;resintdt&quot; To understand how many observations are in your data, we can use nrow() function. Similarly, we can also print the number of columns with ncol(). The function dim() returns both the number of rows and columns at once. nrow() and ncol() return integers dim() returns a vector (rows, columns) &gt; # how many rows and columns are in the dataset? &gt; nrow(dat1) [1] 890 &gt; ncol(dat1) [1] 15 &gt; dim(dat1) [1] 890 15 Another really useful function to use to explore data is the str() or “structure” function. When we run it, we can see all of the column names like the names() function, but now we also see the type of each column as well as any attributes that a column has. The read_sas() function reads in the format and label metadata used in SAS datasets as R object attributes. It is worth noting that the str() function works on most R objects, not just data.frames. &gt; str(dat1) tibble [890 × 15] (S3: tbl_df/tbl/data.frame) $ id : num [1:890] 84681 89253 89499 90166 90291 ... ..- attr(*, &quot;format.sas&quot;)= chr &quot;BEST&quot; $ age : num [1:890] 57 64 75 54 71 71 66 56 50 43 ... ..- attr(*, &quot;format.sas&quot;)= chr &quot;BEST&quot; $ arm : chr [1:890] &quot;F FOLFOX&quot; &quot;F FOLFOX&quot; &quot;F FOLFOX&quot; &quot;G IROX&quot; ... ..- attr(*, &quot;label&quot;)= chr &quot;Treatment Arm&quot; ..- attr(*, &quot;format.sas&quot;)= chr &quot;$&quot; $ sex : chr [1:890] &quot;Male&quot; &quot;Female&quot; &quot;Female&quot; &quot;Female&quot; ... ..- attr(*, &quot;format.sas&quot;)= chr &quot;$&quot; $ futime : num [1:890] 799 97 105 878 31 ... ..- attr(*, &quot;label&quot;)= chr &quot;Follow-up Time&quot; ..- attr(*, &quot;format.sas&quot;)= chr &quot;BEST&quot; $ fustat : num [1:890] 2 2 2 2 2 1 2 2 2 2 ... ..- attr(*, &quot;label&quot;)= chr &quot;Follow-up Status&quot; ..- attr(*, &quot;format.sas&quot;)= chr &quot;STATF&quot; $ ps : num [1:890] 0 1 1 0 2 NA 1 1 1 NA ... ..- attr(*, &quot;label&quot;)= chr &quot;ECOG Performance Score&quot; ..- attr(*, &quot;format.sas&quot;)= chr &quot;BEST&quot; $ hgb : num [1:890] 11.2 12.6 12.5 10.9 9.1 NA 10.5 10.8 13.4 NA ... ..- attr(*, &quot;label&quot;)= chr &quot;Hemoglobin Count&quot; ..- attr(*, &quot;format.sas&quot;)= chr &quot;BEST&quot; $ bmi : num [1:890] NA NA NA NA NA NA NA NA NA NA ... ..- attr(*, &quot;format.sas&quot;)= chr &quot;BEST&quot; $ alkphos : num [1:890] 102 272 169 247 304 NA 196 252 69 NA ... ..- attr(*, &quot;label&quot;)= chr &quot;Alkaline Phosphotase&quot; ..- attr(*, &quot;format.sas&quot;)= chr &quot;BEST&quot; $ ast : num [1:890] 7 62 23 23 115 NA 39 77 13 NA ... ..- attr(*, &quot;label&quot;)= chr &quot;Aspartate Transaminase&quot; ..- attr(*, &quot;format.sas&quot;)= chr &quot;BEST&quot; $ mdqualitys: num [1:890] NA 1 1 1 1 1 0 1 NA 0 ... ..- attr(*, &quot;label&quot;)= chr &quot;LASA QOL&quot; ..- attr(*, &quot;format.sas&quot;)= chr &quot;QOLF&quot; $ ageord : chr [1:890] &quot;50-59&quot; &quot;60-69&quot; &quot;70-79&quot; &quot;50-59&quot; ... ..- attr(*, &quot;label&quot;)= chr &quot;Age Category&quot; ..- attr(*, &quot;format.sas&quot;)= chr &quot;$&quot; $ birthdt : Date[1:890], format: &quot;2007-03-01&quot; &quot;1850-01-01&quot; ... $ resintdt : Date[1:890], format: &quot;1997-01-01&quot; &quot;1997-01-01&quot; ... - attr(*, &quot;label&quot;)= chr &quot;DAT1 &quot; The function str() is what you get when you select the blue triangle next to the data name in the “Environment” panel on the right hand side of RStudio. The fact that Rstudio integrated str() into their IDE (Integrated development environment) really illustrates how useful they think it is. The Rstudio IDE has a ton of really useful features that makes programming in R easier. Using the View() function within Rstudio will cause a new tab to open in the source panel with a view of your data. Hovering over the name of a column will cause the type of column to display. Any label attributes will be displayed in the view, and all columns in the view can be sorted. &gt; View(dat1) Here is some simple code that prints out the variable names and their classes using the functions sapply() and class(). sapply is a function that looks at each element within a list (here, each variable) and runs the specified function (here, class()). Results are returned as a vector. Then, the knitr package includes the kable function which makes pretty default tables, especially for reports. In the output below, the class() function is returning the class of each variable. Typical R classes for variables in a dataset include: character, numeric, integer, Date, logical, factor. More information on classes and data types can be found in Hadley Wickham’s book Advanced R. &gt; library(knitr) &gt; kable(data.frame(Type = sapply(X = dat1, FUN = class))) Type id numeric age numeric arm character sex character futime numeric fustat numeric ps numeric hgb numeric bmi numeric alkphos numeric ast numeric mdqualitys numeric ageord character birthdt Date resintdt Date Other options to this exercise can be found at the end of this document. 1.2.2 Data Exploring Take a closer look at the data using basic summary statistics. Do you notice any strange values? If so, fix them. There are a number of different tools that are available to explore a new dataset. The package summarytools includes the function dfSummary() which provides basic summaries of all of the variables in a dataset. When the summary is written directly to a file, it also provides nice graphical summaries of each variable. &gt; library(summarytools) Registered S3 method overwritten by &#39;pryr&#39;: method from print.bytes Rcpp Warning in fun(libname, pkgname): couldn&#39;t connect to display &quot;:0&quot; system might not have X11 capabilities; in case of errors when using dfSummary(), set st_options(use.x11 = FALSE) Attaching package: &#39;summarytools&#39; The following object is masked from &#39;package:tibble&#39;: view &gt; &gt; # Settings to work well in markdown document (try running default settings &gt; # interactively) &gt; dfSummary(dat1, plain.ascii = FALSE, style = &quot;grid&quot;, graph.col = FALSE, headings = TRUE) 1.2.3 Data Frame Summary 1.2.3.1 dat1 Dimensions: 890 x 15 Duplicates: 0 No Variable Label Stats / Values Freqs (% of Valid) Valid Missing 1 id [numeric] Mean (sd) : 91495.3 (5017.7) min &lt; med &lt; max: 76170 &lt; 91912.5 &lt; 112263 IQR (CV) : 4245 (0.1) 889 distinct values 890 (100%) 0 (0%) 2 age [numeric] Mean (sd) : 60.2 (11.3) min &lt; med &lt; max: 27 &lt; 61 &lt; 88 IQR (CV) : 16 (0.2) 59 distinct values 890 (100%) 0 (0%) 3 arm [character] Treatment Arm 1. A IFL 2. F FOLFOX 3. G IROX 303 (34.0%) 299 (33.6%) 288 (32.4%) 890 (100%) 0 (0%) 4 sex [character] 1. 2 2. F 3. Female 4. Male 2 ( 0.2%) 2 ( 0.2%) 347 (39.0%) 539 (60.6%) 890 (100%) 0 (0%) 5 futime [numeric] Follow-up Time Mean (sd) : 635.3 (487.8) min &lt; med &lt; max: 9 &lt; 516.5 &lt; 2472 IQR (CV) : 546.2 (0.8) 666 distinct values 890 (100%) 0 (0%) 6 fustat [numeric] Follow-up Status Min : 1 Mean : 1.9 Max : 2 1 : 68 ( 7.6%) 2 : 822 (92.4%) 890 (100%) 0 (0%) 7 ps [numeric] ECOG Performance Score Mean (sd) : 0.5 (0.6) min &lt; med &lt; max: 0 &lt; 0 &lt; 2 IQR (CV) : 1 (1.1) 0 : 403 (52.3%) 1 : 324 (42.1%) 2 : 43 ( 5.6%) 770 (86.52%) 120 (13.48%) 8 hgb [numeric] Hemoglobin Count Mean (sd) : 12.4 (1.7) min &lt; med &lt; max: 9 &lt; 12.2 &lt; 18.2 IQR (CV) : 2.5 (0.1) 84 distinct values 770 (86.52%) 120 (13.48%) 9 bmi [numeric] Mean (sd) : 27.1 (5.6) min &lt; med &lt; max: 3.1 &lt; 26.3 &lt; 60.2 IQR (CV) : 6.3 (0.2) 828 distinct values 871 (97.87%) 19 (2.13%) 10 alkphos [numeric] Alkaline Phosphotase Mean (sd) : 173.8 (135.7) min &lt; med &lt; max: 7 &lt; 125 &lt; 1014 IQR (CV) : 126.8 (0.8) 307 distinct values 770 (86.52%) 120 (13.48%) 11 ast [numeric] Aspartate Transaminase Mean (sd) : 36.5 (27.1) min &lt; med &lt; max: 7 &lt; 27 &lt; 205 IQR (CV) : 22.8 (0.7) 114 distinct values 770 (86.52%) 120 (13.48%) 12 mdqualitys [numeric] LASA QOL Min : 0 Mean : 0.9 Max : 1 0 : 85 (10.7%) 1 : 707 (89.3%) 792 (88.99%) 98 (11.01%) 13 ageord [character] Age Category 1. 20-29 2. 30-39 3. 40-49 4. 50-59 5. 60-69 6. 70-79 7. 80-89 12 ( 1.4%) 40 ( 4.5%) 117 (13.2%) 256 (28.8%) 288 (32.4%) 162 (18.2%) 15 ( 1.7%) 890 (100%) 0 (0%) 14 birthdt [Date] min : 1850-01-01 med : 1966-09-22 max : 2015-04-06 range : 165y 3m 5d 638 distinct values 890 (100%) 0 (0%) 15 resintdt [Date] min : 1996-12-31 med : 1997-01-01 max : 2014-02-19 range : 17y 1m 19d 50 distinct values 812 (91.24%) 78 (8.76%) &gt; &gt; # Save the results to an external file (includes plots!) &gt; print(dfSummary(dat1), file = &quot;dat1.html&quot;) Warning in png(png_loc &lt;- tempfile(fileext = &quot;.png&quot;), width = 150 * graph.magnif, : unable to open connection to X11 display &#39;&#39; Warning in png(png_loc &lt;- tempfile(fileext = &quot;.png&quot;), width = 150 * graph.magnif, : unable to open connection to X11 display &#39;&#39; Warning in png(png_loc &lt;- tempfile(fileext = &quot;.png&quot;), width = 150 * graph.magnif, : unable to open connection to X11 display &#39;&#39; Warning in png(png_loc &lt;- tempfile(fileext = &quot;.png&quot;), width = 150 * graph.magnif, : unable to open connection to X11 display &#39;&#39; Warning in png(png_loc &lt;- tempfile(fileext = &quot;.png&quot;), width = 150 * graph.magnif, : unable to open connection to X11 display &#39;&#39; Warning in png(png_loc &lt;- tempfile(fileext = &quot;.png&quot;), width = 150 * graph.magnif, : unable to open connection to X11 display &#39;&#39; Warning in png(png_loc &lt;- tempfile(fileext = &quot;.png&quot;), width = 150 * graph.magnif, : unable to open connection to X11 display &#39;&#39; Warning in png(png_loc &lt;- tempfile(fileext = &quot;.png&quot;), width = 150 * graph.magnif, : unable to open connection to X11 display &#39;&#39; Warning in png(png_loc &lt;- tempfile(fileext = &quot;.png&quot;), width = 150 * graph.magnif, : unable to open connection to X11 display &#39;&#39; Warning in png(png_loc &lt;- tempfile(fileext = &quot;.png&quot;), width = 150 * graph.magnif, : unable to open connection to X11 display &#39;&#39; Warning in png(png_loc &lt;- tempfile(fileext = &quot;.png&quot;), width = 150 * graph.magnif, : unable to open connection to X11 display &#39;&#39; Warning in png(png_loc &lt;- tempfile(fileext = &quot;.png&quot;), width = 150 * graph.magnif, : unable to open connection to X11 display &#39;&#39; Warning in png(png_loc &lt;- tempfile(fileext = &quot;.png&quot;), width = 150 * graph.magnif, : unable to open connection to X11 display &#39;&#39; Warning in png(png_loc &lt;- tempfile(fileext = &quot;.png&quot;), width = 150 * graph.magnif, : unable to open connection to X11 display &#39;&#39; Warning in png(png_loc &lt;- tempfile(fileext = &quot;.png&quot;), width = 150 * graph.magnif, : unable to open connection to X11 display &#39;&#39; Switching method to &#39;browser&#39; Output file written: /home/atkinson/education/R_project_recipes/dat1.html See the external file version. Another option is to use the tableby() function that is available in the Mayo package arsenal. Tableby is a fantastic function for quick summaries for data exploration or reporting “table 1” describing the cohort. This function allows you to summarize the data stratified by some “by” variable or overall without any stratification. The code ~ sex + arm + age + bmi is a formula. If you wanted to stratify by a variable you would list the stratification variable on the left hand side of the ~. The tableby function does all the calculations, but it doesn’t create the information in a nice format. The summary() function pulls everything together into a nice table. Note that when you type summary here you are actually using summary.tableby(). This is important when looking for help with summarizing the tableby output. If you want to look at the summary in your console window, you might want to use summary(tab1, text=T). In order for the table to look nice within an R markdown (knitr) report, you just need to specify results=\"asis\" when creating the r chunk. This changes the layout slightly (compresses it) and bolds the variable names. &gt; library(arsenal) &gt; tab1 &lt;- tableby(~sex + arm + age + bmi, data = dat1) &gt; class(tab1) [1] “tableby” “arsenal_table” &gt; summary(tab1, title = &quot;Baseline and patient characteristics&quot;) Baseline and patient characteristics Overall (N=890) sex    2 2 (0.2%)    F 2 (0.2%)    Female 347 (39.0%)    Male 539 (60.6%) Treatment Arm    A IFL 303 (34.0%)    F FOLFOX 299 (33.6%)    G IROX 288 (32.4%) age    Mean (SD) 60.152 (11.342)    Range 27.000 - 88.000 bmi    N-Miss 19    Mean (SD) 27.106 (5.620)    Range 3.060 - 60.243 If you want to examine every variable in dat you can use the shortcut .. &gt; tab1 &lt;- tableby(~., data = dat1) Based on these summaries, it appears that sex was not coded correctly and needs to be fixed. Our investigator confirms that 2 is supposed to be female. To correct this, we will pull out all the values in the variable sex within the dat1 dataset that are equal to 2 or F (dat1$sex[dat1$sex %in% c('2','F')]) and assign those values to be equal to “Female” (&lt;- 'Female'). &gt; table(dat1$sex) 2 F Female Male 2 2 347 539 &gt; &gt; # For those observations that are 2 or F, change them to Female &gt; dat1$sex[dat1$sex %in% c(&quot;2&quot;, &quot;F&quot;)] &lt;- &quot;Female&quot; &gt; &gt; table(dat1$sex) Female Male 351 539 One of the tricky functions in R for SAS programmers is the ifelse() function which differs from if() {} else {}. Suppose that you believe that all observations over a certain cutoff are errors and you want to set them equal to missing. The code below uses ifelse. The first argument creates a logical True/False variable. For those observations where the “test” is TRUE, use the value in the “yes” field and for those observations where the “test” is FALSE, use the value in the “no” field. &gt; ast &lt;- dat1$ast &gt; summary(ast) Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s 7.00 20.00 27.00 36.46 42.75 205.00 120 &gt; ast2 &lt;- ifelse(test = ast &gt; 45, yes = NA, no = ast) &gt; summary(ast2) Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s 7.00 19.00 24.00 25.21 31.00 45.00 286 If instead I was creating a loop and I had one logical value, then I would do something like the following using if() else(). &gt; group &lt;- &quot;A IFL&quot; &gt; &gt; if (group == &quot;A IFL&quot;) { + summary(ast) + } else { + summary(ast2) + } Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s 7.00 20.00 27.00 36.46 42.75 205.00 120 An alternative to ifelse is the case_when() function in the dplyr package. It is particularly useful when you have multiple nested “ifelse” statements. For instance, this is another alternative for fixing the code for sex. &gt; dat1$sex &lt;- case_when(dat1$sex == 2 ~ &quot;Female&quot;, dat1$sex == &quot;F&quot; ~ &quot;Female&quot;, TRUE ~ + dat1$sex) Oops, there is a duplicate observation in the data. Confirm the data is the same for all the variables and remove one of the duplicates. Mistakes in data entry occur all the time. It is wise to check for duplicate records and/or more than one record per unique patient. There are a few different tools that can be used to check for duplicate observations including the functions duplicated() and dplyr::distinct(). &gt; # count how many times each id appears in dat1 &gt; table(table(dat1$id)) 1 2 888 1 &gt; &gt; &gt; # This next line of code first identifies which ids are duplicated: &gt; # &#39;duplicated(dat1$id)&#39; Then, it selects those ids from &#39;dat1$id&#39; and returns &gt; # only one instance of each duplicated ids using &#39;unique()&#39;. &gt; &gt; tmp &lt;- unique(dat1$id[duplicated(dat1$id)]) &gt; &gt; # which rows have a duplicate? &gt; dup.rows &lt;- which(dat1$id %in% tmp) &gt; &gt; # show a portion of the data with the duplicates - which version do you keep? &gt; # the kable function is available in the knitr package &gt; kable(dat1[dup.rows, c(&quot;id&quot;, &quot;age&quot;, &quot;arm&quot;, &quot;sex&quot;, &quot;bmi&quot;)]) id age arm sex bmi 101106 79 F FOLFOX Female 3.059935 101106 79 F FOLFOX Female 30.599346 This same code can be run using the following dplyr commands. It also illustrates the use of “piping”, which is what the 3 character string %&gt;% is called. Basically, it allows you to combine a bunch of commands together without having to save out temporary datasets. The filter command keeps only those observations where the condition is true. The select function keeps only certain variables. &gt; # Using dplyr code this would be &gt; dat1 %&gt;% filter(id %in% tmp) %&gt;% select(id, age, arm, sex, bmi) %&gt;% kable() id age arm sex bmi 101106 79 F FOLFOX Female 3.059935 101106 79 F FOLFOX Female 30.599346 Now check to see if the observations are a complete duplicate or not. &gt; # When you use `duplicated()` on a data.frame, it will test for completely &gt; # identical rows. &gt; table(duplicated(dat1)) FALSE 890 &gt; &gt; # remove rows with duplicate values (2 different approaches) Both approaches will &gt; # return the first instance of a row and will exclude any duplicated rows. This &gt; # is similar to `FIRST.` in SAS. &gt; dim(dat1) [1] 890 15 &gt; &gt; dat2 &lt;- dat1[!duplicated(dat1), ] &gt; dim(dat2) [1] 890 15 Summarize age, gender, bmi, … by the treatment variable using parametric statistics Again, this is an instance where tableby produces a nice table. Here the variable arm is listed on the left-hand side of the formula. The option pfootnote=TRUE indicates that the summary table should show a footnote indicating what test was run. &gt; tab1 &lt;- tableby(arm ~ age + sex + ps + bmi + alkphos + mdqualitys + ageord + birthdt, + data = dat2) &gt; summary(tab1, pfootnote = TRUE, total = FALSE) A IFL (N=303) F FOLFOX (N=299) G IROX (N=288) p value age 0.5851    Mean (SD) 59.696 (11.365) 60.652 (11.422) 60.111 (11.253)    Range 27.000 - 88.000 27.000 - 88.000 28.000 - 84.000 sex 0.1752    Female 107 (35.3%) 127 (42.5%) 117 (40.6%)    Male 196 (64.7%) 172 (57.5%) 171 (59.4%) ECOG Performance Score 0.7811    N-Miss 45 39 36    Mean (SD) 0.512 (0.600) 0.538 (0.598) 0.548 (0.607)    Range 0.000 - 2.000 0.000 - 2.000 0.000 - 2.000 bmi 0.7451    N-Miss 6 9 4    Mean (SD) 27.278 (5.493) 27.112 (5.499) 26.920 (5.883)    Range 14.053 - 53.008 3.060 - 49.130 16.071 - 60.243 Alkaline Phosphotase 0.7071    N-Miss 45 39 36    Mean (SD) 170.612 (124.842) 171.377 (133.671) 179.663 (148.110)    Range 13.000 - 858.000 18.000 - 1014.000 7.000 - 982.000 LASA QOL 0.9371    N-Miss 31 35 32    Mean (SD) 0.890 (0.314) 0.890 (0.313) 0.898 (0.303)    Range 0.000 - 1.000 0.000 - 1.000 0.000 - 1.000 Age Category 0.9942    20-29 3 (1.0%) 4 (1.3%) 5 (1.7%)    30-39 15 (5.0%) 12 (4.0%) 13 (4.5%)    40-49 46 (15.2%) 36 (12.0%) 35 (12.2%)    50-59 85 (28.1%) 89 (29.8%) 82 (28.5%)    60-69 98 (32.3%) 96 (32.1%) 94 (32.6%)    70-79 52 (17.2%) 56 (18.7%) 54 (18.8%)    80-89 4 (1.3%) 6 (2.0%) 5 (1.7%) birthdt 0.6533    Median 1966-10-09 1969-01-01 1964-10-02    Range 1850-01-01 - 2015-04-06 1850-01-01 - 2013-11-03 1850-01-01 - 2014-01-01 Linear Model ANOVA Pearson’s Chi-squared test Kruskal-Wallis rank sum test Do the summary statistics make sense for each variable? If not, modify them so that the default summaries fit the data. These are the variables that are not creating the correct summaries LASA QOL (mdqualitys) Range of values from 0-1 ECOG Performance Score (ps) Range of values from 0 - 2 0 = Asymptomatic, 1 = Symptomatic but ambulatory, 2 = Symptomatic, &lt;50% in bed during the day Age group (ageord) Age groups, character strings (20-29, … 80-89) The variables mdqualitys and ps should not be treated as numeric values and summaries for ageord should recognize that 20-29 is less than 30-39 (hence the use of the “ordered” function instead of “factor”). &gt; # Since the summaries performed by `tableby` are dependent on the class of the &gt; # variable, if we change the class, we change the how `tableby` treats the &gt; # variable. &gt; &gt; # change mdqualitys to a factor &gt; dat2$mdqualitys &lt;- factor(dat2$mdqualitys, levels = c(0, 1), labels = c(&quot;Deficient&quot;, + &quot;Not Deficient&quot;)) &gt; &gt; # change ps to an ordered factor where 0 &lt; 1 &lt; 2 &gt; dat2$ps &lt;- ordered(dat2$ps, levels = 0:2, labels = 0:2) &gt; &gt; # change ageord to an ordered factor &gt; dat2$ageord &lt;- ordered(dat2$ageord) Change the label for the variables age and bmi When reading data in from SAS, variable labels are retained and stored in the attribute of the variable. Usually in R, when a data.frame is subsetted these labels disappear. Therefore it is useful to keep a separate object storing the variables and their labels. If you have attached the package arsenal we have modified this behavior so labels do not disappear. You can assign columns metadata, like a label, that describes them using attributes. If you want to modify/add a specific label, there are a couple of ways to do that. The function tableby will look for label attributes and will automatically use them in the summaries. Another way to modify/add is using the attr() function. &gt; # The labels() function in arsenal shows all labels of a data frame &gt; labels(dat2)$bmi NULL &gt; labels(dat2)$bmi &lt;- &quot;Body Mass Index&quot; &gt; &gt; # Modify the actual attribute for the variable &gt; attr(dat2$age, &quot;label&quot;) NULL &gt; attr(dat2$age, &quot;label&quot;) &lt;- &quot;Age at baseline&quot; More information about labels can be found in the arsenal vignette on that topic. Now change the summary statistics to be non-parametric in the table. Using the function tableby.control() you can define which summary statistics and tests you want to appear for each type of variable (look at the help page of tableby.control, try ?tableby.control for more details). &gt; # change summary statistics to be non-parametric by using numeric.stats in &gt; # tableby.control also, revise the number of decimal places, remove chi-squared &gt; # correction create a tableby.control object to use later &gt; mycontrol &lt;- tableby.control(numeric.stats = c(&quot;Nmiss&quot;, &quot;medianq1q3&quot;), digits = 1, + chisq.correct = FALSE) &gt; &gt; tab2 &lt;- tableby(arm ~ age + sex + ps + bmi + alkphos + mdqualitys + ageord + birthdt, + data = dat2, control = mycontrol) &gt; summary(tab2, pfootnote = TRUE) A IFL (N=303) F FOLFOX (N=299) G IROX (N=288) Total (N=890) p value Age at baseline 0.5851    Median (Q1, Q3) 61.0 (53.0, 68.0) 61.0 (52.5, 69.0) 61.0 (53.0, 68.2) 61.0 (53.0, 69.0) sex 0.1752    Female 107 (35.3%) 127 (42.5%) 117 (40.6%) 351 (39.4%)    Male 196 (64.7%) 172 (57.5%) 171 (59.4%) 539 (60.6%) ps 0.7803    N-Miss 45 39 36 120    0 140 (54.3%) 134 (51.5%) 129 (51.2%) 403 (52.3%)    1 104 (40.3%) 112 (43.1%) 108 (42.9%) 324 (42.1%)    2 14 (5.4%) 14 (5.4%) 15 (6.0%) 43 (5.6%) Body Mass Index 0.7451    N-Miss 6 9 4 19    Median (Q1, Q3) 26.3 (23.6, 30.1) 26.5 (23.7, 29.7) 25.8 (23.0, 29.2) 26.3 (23.5, 29.8) Alkaline Phosphotase 0.7071    N-Miss 45 39 36 120    Median (Q1, Q3) 128.0 (83.2, 212.8) 122.0 (87.8, 207.5) 122.0 (87.8, 219.8) 125.0 (86.0, 212.8) mdqualitys 0.9362    N-Miss 31 35 32 98    Deficient 30 (11.0%) 29 (11.0%) 26 (10.2%) 85 (10.7%)    Not Deficient 242 (89.0%) 235 (89.0%) 230 (89.8%) 707 (89.3%) ageord 0.6373    20-29 3 (1.0%) 4 (1.3%) 5 (1.7%) 12 (1.3%)    30-39 15 (5.0%) 12 (4.0%) 13 (4.5%) 40 (4.5%)    40-49 46 (15.2%) 36 (12.0%) 35 (12.2%) 117 (13.1%)    50-59 85 (28.1%) 89 (29.8%) 82 (28.5%) 256 (28.8%)    60-69 98 (32.3%) 96 (32.1%) 94 (32.6%) 288 (32.4%)    70-79 52 (17.2%) 56 (18.7%) 54 (18.8%) 162 (18.2%)    80-89 4 (1.3%) 6 (2.0%) 5 (1.7%) 15 (1.7%) birthdt 0.6534    Median 1966-10-09 1969-01-01 1964-10-02 1966-09-22    Range 1850-01-01 - 2015-04-06 1850-01-01 - 2013-11-03 1850-01-01 - 2014-01-01 1850-01-01 - 2015-04-06 Linear Model ANOVA Pearson’s Chi-squared test Trend test for ordinal variables Kruskal-Wallis rank sum test We can see that Age Group, ECOG Performance Score, and LASA QOL are now summarized appropriately and the default tests have changed for these variables. Also, the labels for BMI and age have changed. Another way to add labels is to use the labelTranslations option within summary.tableby(). Here this example assumes that you have a list describing the variable labels (see the example at the end of the document for details on how to create the vlabels list). &gt; # Use labelTranslations to add labels, ignore warning &gt; summary(tab2, labelTranslations = vlabels, pfootnote) Run the table separately for males only (subsetting on the fly instead of creating separate datasets). In your report, add some text describing how many males and how many females you have. &gt; tab2_males &lt;- tableby(arm ~ age + ps + bmi + alkphos + mdqualitys + ageord + birthdt, + data = dat2, control = mycontrol, subset = sex == &quot;Male&quot;) &gt; summary(tab2_males, pfootnote = TRUE, title = &quot;Males only&quot;) Males only A IFL (N=196) F FOLFOX (N=172) G IROX (N=171) Total (N=539) p value Age at baseline 0.7171    Median (Q1, Q3) 61.0 (53.8, 68.0) 61.0 (53.0, 69.0) 62.0 (53.5, 69.5) 61.0 (53.0, 69.0) ps 0.5082    N-Miss 32 16 24 72    0 94 (57.3%) 80 (51.3%) 79 (53.7%) 253 (54.2%)    1 64 (39.0%) 68 (43.6%) 61 (41.5%) 193 (41.3%)    2 6 (3.7%) 8 (5.1%) 7 (4.8%) 21 (4.5%) Body Mass Index 0.8721    N-Miss 4 5 3 12    Median (Q1, Q3) 26.8 (24.3, 30.0) 26.7 (24.1, 30.0) 26.3 (24.0, 29.2) 26.5 (24.1, 29.9) Alkaline Phosphotase 0.7631    N-Miss 32 16 24 72    Median (Q1, Q3) 125.0 (82.0, 205.2) 123.5 (89.0, 195.2) 111.0 (87.0, 196.5) 122.0 (86.0, 199.5) mdqualitys 0.8613    N-Miss 17 19 19 55    Deficient 21 (11.7%) 17 (11.1%) 15 (9.9%) 53 (11.0%)    Not Deficient 158 (88.3%) 136 (88.9%) 137 (90.1%) 431 (89.0%) ageord 0.6022    20-29 2 (1.0%) 2 (1.2%) 1 (0.6%) 5 (0.9%)    30-39 8 (4.1%) 7 (4.1%) 8 (4.7%) 23 (4.3%)    40-49 29 (14.8%) 25 (14.5%) 20 (11.7%) 74 (13.7%)    50-59 58 (29.6%) 48 (27.9%) 49 (28.7%) 155 (28.8%)    60-69 63 (32.1%) 56 (32.6%) 54 (31.6%) 173 (32.1%)    70-79 33 (16.8%) 29 (16.9%) 35 (20.5%) 97 (18.0%)    80-89 3 (1.5%) 5 (2.9%) 4 (2.3%) 12 (2.2%) birthdt 0.0424    Median 1969-01-01 1972-02-07 1965-01-01 1969-01-01    Range 1850-01-01 - 2015-04-06 1850-01-01 - 2013-11-03 1850-01-01 - 2014-01-01 1850-01-01 - 2015-04-06 Linear Model ANOVA Trend test for ordinal variables Pearson’s Chi-squared test Kruskal-Wallis rank sum test &gt; &gt; # either calculate these ahead of time or on-the-fly &gt; nfemale &lt;- sum(dat2$sex == &quot;Female&quot;) &gt; nmales &lt;- sum(dat2$sex == &quot;Male&quot;) The study sample consists of 890 observations, of which 539 are men and 351 are women. How many people have the combinations of ps, sex, and treatment arm? The freqlist() function, also available in the arsenal package, provides summaries similar to what you might get with proc freq; table a*b*c / list in SAS. The sparse option shows all combinations. &gt; summary(freqlist(~ps + sex + arm, data = dat2, sparse = TRUE)) ps sex Treatment Arm Freq Cumulative Freq Percent Cumulative Percent 0 Female A IFL 46 46 5.17 5.17 F FOLFOX 54 100 6.07 11.24 G IROX 50 150 5.62 16.85 Male A IFL 94 244 10.56 27.42 F FOLFOX 80 324 8.99 36.40 G IROX 79 403 8.88 45.28 1 Female A IFL 40 443 4.49 49.78 F FOLFOX 44 487 4.94 54.72 G IROX 47 534 5.28 60.00 Male A IFL 64 598 7.19 67.19 F FOLFOX 68 666 7.64 74.83 G IROX 61 727 6.85 81.69 2 Female A IFL 8 735 0.90 82.58 F FOLFOX 6 741 0.67 83.26 G IROX 8 749 0.90 84.16 Male A IFL 6 755 0.67 84.83 F FOLFOX 8 763 0.90 85.73 G IROX 7 770 0.79 86.52 NA Female A IFL 13 783 1.46 87.98 F FOLFOX 23 806 2.58 90.56 G IROX 12 818 1.35 91.91 Male A IFL 32 850 3.60 95.51 F FOLFOX 16 866 1.80 97.30 G IROX 24 890 2.70 100.00 Many times we are interested in the frequency of certain combinations of variables. The code below illustrates the power of the group_by() and count() available in the dplyr package. This is a handy way to do several commands together. In this example, the code reads as: use the dataset dat2 stratify the data by a combination of sex, arm, and ps count how many rows there are in each strata print out the results using the kable() function &gt; dat2 %&gt;% group_by(sex, arm, ps) %&gt;% count() %&gt;% kable() sex arm ps n Female A IFL 0 46 Female A IFL 1 40 Female A IFL 2 8 Female A IFL NA 13 Female F FOLFOX 0 54 Female F FOLFOX 1 44 Female F FOLFOX 2 6 Female F FOLFOX NA 23 Female G IROX 0 50 Female G IROX 1 47 Female G IROX 2 8 Female G IROX NA 12 Male A IFL 0 94 Male A IFL 1 64 Male A IFL 2 6 Male A IFL NA 32 Male F FOLFOX 0 80 Male F FOLFOX 1 68 Male F FOLFOX 2 8 Male F FOLFOX NA 16 Male G IROX 0 79 Male G IROX 1 61 Male G IROX 2 7 Male G IROX NA 24 Fancier: create a formula from a list of variables that can used in tableby (hint: explore formulize) The arsenal package has the function formulize() which allows you to create a formula and use it repeatedly. This can be especially helpful when you have a list of variables that you want to loop over or summarize in different ways. &gt; labvars &lt;- c(&quot;hgb&quot;, &quot;alkphos&quot;, &quot;ast&quot;) &gt; myform &lt;- formulize(&quot;sex&quot;, labvars) &gt; myform sex ~ hgb + alkphos + ast &gt; &gt; summary(tableby(myform, data = dat2)) Female (N=351) Male (N=539) Total (N=890) p value Hemoglobin Count &lt; 0.001    N-Miss 48 72 120    Mean (SD) 11.956 (1.446) 12.620 (1.796) 12.359 (1.698)    Range 9.000 - 17.900 9.000 - 18.200 9.000 - 18.200 Alkaline Phosphotase 0.342    N-Miss 48 72 120    Mean (SD) 179.607 (131.827) 170.086 (138.099) 173.832 (135.659)    Range 7.000 - 771.000 13.000 - 1014.000 7.000 - 1014.000 Aspartate Transaminase 0.406    N-Miss 48 72 120    Mean (SD) 37.475 (28.437) 35.809 (26.288) 36.465 (27.148)    Range 10.000 - 178.000 7.000 - 205.000 7.000 - 205.000 Other options to this exercise can be found at the end of this document. 1.2.4 Plotting There are three main plotting systems in R: basic, ggplot2, and lattice. It is useful to know at least the basic and ggplot2 approaches to plotting because sometimes one tool is better than the other. The examples below include both basic and ggplot2 code so that you can compare the results. There are two basic and fundamental parts of a ggplot call: the aes() function, which defines the plots aesthetics, and a call to a geom_*() function. Basically the aes() function defines the variables to be used on the x and y axes (and optionally a group variable). The geom_*() functions will define what type of plot to use (boxplot, scatterplot, etc.). 1.2.4.1 Boxplots Create a boxplot of bmi &gt; # code using basic R &gt; boxplot(dat2$bmi) &gt; &gt; # code using ggplot &gt; library(ggplot2) &gt; ggplot(dat2, aes(x = &quot;total&quot;, y = bmi)) + geom_boxplot() Warning: Removed 19 rows containing non-finite values (stat_boxplot). Now create the boxplots stratified by the treatment arm &gt; # code using basic R &gt; boxplot(bmi ~ arm, data = dat2) &gt; &gt; # code using ggplot &gt; ggplot(dat2, aes(x = arm, y = bmi)) + geom_boxplot() Warning: Removed 19 rows containing non-finite values (stat_boxplot). Modify the axis labels and add a title to your plot. &gt; # code using basic R &gt; boxplot(bmi ~ arm, data = dat2, xlab = &quot; &quot;, ylab = &quot;BMI at baseline&quot;, main = &quot;BMI distribution stratified by treatment group&quot;) &gt; &gt; # code using ggplot &gt; ggplot(dat2, aes(x = arm, y = bmi)) + geom_boxplot() + xlab(&quot; &quot;) + ylab(&quot;BMI at baseline&quot;) + + ggtitle(&quot;BMI distribution stratified by treatment group&quot;) Warning: Removed 19 rows containing non-finite values (stat_boxplot). 1.2.4.2 Scatterplots Now make two scatterplots of age versus bmi with different colors indicating treatment The call to as.numeric(as.factor(arm)) turns the levels of arm to a factor which is essentially a numeric variables with formats. The call to as.numeric then changes the factor to a number, and the numbers correspond to different colors (1=black, 2=red, 3=green, 4=blue, 5=lightblue, 6=pink, 7=yellow, 8=gray). &gt; # code using basic R &gt; plot(bmi ~ age, data = dat2, col = as.numeric(as.factor(arm))) &gt; &gt; # code using ggplot &gt; ggplot(dat2, aes(age, bmi, color = arm)) + geom_point() Warning: Removed 19 rows containing missing values (geom_point). Create these same scatterplots, side-by-side, separately for males and females &gt; # code using basic R &gt; par(mfrow = c(1, 2)) &gt; plot(bmi ~ age, data = dat2[dat2$sex == &quot;Female&quot;, ], col = as.numeric(as.factor(arm)), + main = &quot;Females&quot;) &gt; plot(bmi ~ age, data = dat2[dat2$sex == &quot;Male&quot;, ], col = as.numeric(as.factor(arm)), + main = &quot;Males&quot;) &gt; par(mfrow = c(1, 1)) &gt; &gt; # code using ggplot &gt; ggplot(dat2, aes(age, bmi, color = arm)) + geom_point() + facet_grid(~sex) Warning: Removed 19 rows containing missing values (geom_point). Fancier: How would you add a regression line to these plots? How about smoothers? The code using base R graphics can be found further down at the end of this document. &gt; # code using ggplot -- Regression lines &gt; ggplot(dat2, aes(age, bmi, color = arm)) + geom_point() + facet_grid(~sex) + geom_smooth(method = &quot;lm&quot;) `geom_smooth()` using formula &#39;y ~ x&#39; Warning: Removed 19 rows containing non-finite values (stat_smooth). Warning: Removed 19 rows containing missing values (geom_point). &gt; &gt; # -- Smoothers &gt; ggplot(dat2, aes(age, bmi, color = arm)) + geom_point() + facet_grid(~sex) + geom_smooth() `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; Warning: Removed 19 rows containing non-finite values (stat_smooth). Warning: Removed 19 rows containing missing values (geom_point). &gt; &gt; # -- Smoothers removing the confidence bands &gt; ggplot(dat2, aes(age, bmi, color = arm)) + geom_point() + facet_grid(~sex) + geom_smooth(se = FALSE) `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; Warning: Removed 19 rows containing non-finite values (stat_smooth). Warning: Removed 19 rows containing missing values (geom_point). There are many formating options for ggplot including theme_bw and the package [ggthemes[(https://rdrr.io/cran/ggthemes/)] which includes extra themes, geoms, and scales for ggplot2. Below, see how the plot has changed by just indicating the plotting theme. Another addition is the alpha term which lightens the points (default=1). &gt; ggplot(dat2, aes(age, bmi, color = arm)) + geom_point(alpha = 0.2) + facet_grid(~sex) + + geom_smooth(se = FALSE) + theme_bw() `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; Warning: Removed 19 rows containing non-finite values (stat_smooth). Warning: Removed 19 rows containing missing values (geom_point). 1.2.5 Basic Modeling Run a simple linear regression model predicting bmi with a covariate that is coded as 1/2. Now re-do it with the covariate coded as a factor. Did the answer change? First create a numeric version of sex with the values 1 and 2 (for illustration purposes only). This can be done by changing the variable sex from character to a factor, then changing the factor to numeric. &gt; # Create a version of sex that is coded 1/2 &gt; dat2$sex.f &lt;- factor(dat2$sex) &gt; dat2$sex12 &lt;- as.numeric(dat2$sex.f) &gt; &gt; table(dat2$sex12, dat2$sex.f) Female Male 1 351 0 2 0 539 Next, fit a linear regression model using the function lm(). The lm() function uses two main arguments - a formula and a dataset. &gt; # Fit a linear regression model using the the two different versions of sex &gt; fit1 &lt;- lm(bmi ~ sex12, data = dat2) &gt; fit2 &lt;- lm(bmi ~ sex.f, data = dat2) There are a number of extractor functions for models, meaning that they can be used to extract information from a model. One example is coef() which extracts the coefficients. &gt; # Compare the coefficients &gt; coef(fit1) (Intercept) sex12 25.6960705 0.8783982 &gt; coef(fit2) (Intercept) sex.fMale 26.5744687 0.8783982 The summary() function shown below is actually using summary.lm(). &gt; # Look at a standard model summary &gt; summary(fit1) Call: lm(formula = bmi ~ sex12, data = dat2) Residuals: Min 1Q Median 3Q Max -23.515 -3.610 -1.038 2.769 32.790 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 25.6961 0.6521 39.40 &lt;2e-16 *** sex12 0.8784 0.3887 2.26 0.0241 * --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 5.607 on 869 degrees of freedom (19 observations deleted due to missingness) Multiple R-squared: 0.005844, Adjusted R-squared: 0.0047 F-statistic: 5.108 on 1 and 869 DF, p-value: 0.02406 Other options to this exercise can be found at the end of this document. 1.2.6 Data Import, revisited Now read the data in from Excel. What is different about the datasets? Using the readxl package we are able to read in Excel data using the read_xls() function. &gt; # Clean copy of SAS data &gt; library(haven) &gt; sas_dat1 &lt;- read_sas(&quot;data/dat1.sas7bdat&quot;) &gt; &gt; # Use the readxl package to read in Excel data &gt; library(readxl) &gt; &gt; if (!file.exists(&quot;data/dat1.xls&quot;)) { + urlfile &lt;- &quot;https://raw.githubusercontent.com/bethatkinson/R_project_recipes/data/dat1.xls&quot; + if (!dir.exists(&quot;data&quot;)) + dir.create(&quot;data&quot;) + download.file(urlfile, destfile = &quot;data/dat1.xls&quot;) + } &gt; excel_dat1 &lt;- read_excel(&quot;data/dat1.xls&quot;) The arsenal package has a function called comparedf() which is similar to Proc Compare in SAS. It compares two data.frame objects and reports any differences. &gt; # Compare data.frames dat1 and excel_dat1 using comparedf &gt; tmp &lt;- comparedf(sas_dat1, excel_dat1) &gt; &gt; # Brief overview of differences &gt; print(tmp) Compare Object Function Call: comparedf(x = sas_dat1, y = excel_dat1) Shared: 8 non-by variables and 889 observations. Not shared: 14 variables and 1 observations. Differences found in 8/8 variables compared. 8 variables compared have non-identical attributes. &gt; &gt; # More detailed summary of differences &gt; summary(tmp) Table 1.1: Summary of data.frames version arg ncol nrow x sas_dat1 15 890 y excel_dat1 15 889 Table 1.1: Summary of overall comparison statistic value Number of by-variables 0 Number of non-by variables in common 8 Number of variables compared 8 Number of variables in x but not y 7 Number of variables in y but not x 7 Number of variables compared with some values unequal 8 Number of variables compared with all values equal 0 Number of observations in common 889 Number of observations in x but not y 1 Number of observations in y but not x 0 Number of observations with some compared variables unequal 889 Number of observations with all compared variables equal 0 Number of values unequal 6236 Table 1.1: Variables not shared version variable position class x futime 5 numeric x fustat 6 numeric x alkphos 10 numeric x mdqualitys 12 numeric x ageord 13 character x birthdt 14 Date x resintdt 15 Date y fu.time 5 numeric y fu.stat 6 numeric y alk.phos 10 numeric y mdquality.s 12 numeric y age.ord 13 character y birth.dt 14 character y resint.dt 15 character Table 1.1: Other variables not compared No other variables not compared Table 1.1: Observations not shared version ..row.names.. observation x 890 890 Table 1.1: Differences detected by variable var.x var.y n NAs id id 888 0 age age 866 0 arm arm 889 0 sex sex 441 0 ps ps 543 210 hgb hgb 862 210 bmi bmi 885 32 ast ast 862 210 Table 1.1: Differences detected (6186 not shown) var.x var.y ..row.names.. values.x values.y row.x row.y id id 1 84681 90523 1 1 id id 2 89253 89582 2 2 id id 3 89499 91375 3 3 id id 4 90166 94287 4 4 id id 5 90291 95327 5 5 id id 6 91450 91923 6 6 id id 7 91486 93176 7 7 id id 8 91504 91724 8 8 id id 9 91724 92965 9 9 id id 10 92079 92389 10 10 age age 1 57 65 1 1 age age 3 75 62 3 3 age age 4 54 53 4 4 age age 5 71 52 5 5 age age 6 71 51 6 6 age age 7 66 31 7 7 age age 8 56 50 8 8 age age 9 50 68 9 9 age age 10 43 58 10 10 age age 11 51 43 11 11 arm arm 1 F FOLFOX A: IFL 1 1 arm arm 2 F FOLFOX F: FOLFOX 2 2 arm arm 3 F FOLFOX A: IFL 3 3 arm arm 4 G IROX F: FOLFOX 4 4 arm arm 5 A IFL F: FOLFOX 5 5 arm arm 6 F FOLFOX G: IROX 6 6 arm arm 7 A IFL F: FOLFOX 7 7 arm arm 8 A IFL G: IROX 8 8 arm arm 9 G IROX F: FOLFOX 9 9 arm arm 10 A IFL A: IFL 10 10 sex sex 4 Female Male 4 4 sex sex 6 Female Male 6 6 sex sex 7 Male Female 7 7 sex sex 11 Female Male 11 11 sex sex 15 Female Male 15 15 sex sex 17 Male Female 17 17 sex sex 19 Female Male 19 19 sex sex 20 Female Male 20 20 sex sex 22 Female Male 22 22 sex sex 23 Female Male 23 23 ps ps 2 1 0 2 2 ps ps 5 2 1 5 5 ps ps 6 NA 1 6 6 ps ps 9 1 0 9 9 ps ps 11 0 NA 11 11 ps ps 16 0 1 16 16 ps ps 17 1 0 17 17 ps ps 18 1 NA 18 18 ps ps 19 1 0 19 19 ps ps 20 0 1 20 20 Table 1.1: Non-identical attributes var.x var.y name id id format.sas age age format.sas arm arm format.sas arm arm label sex sex format.sas ps ps format.sas ps ps label hgb hgb format.sas hgb hgb label bmi bmi format.sas ast ast format.sas ast ast label &gt; &gt; # now compare after matching by id &gt; tmp2 &lt;- comparedf(x = sas_dat1, y = excel_dat1, by = &quot;id&quot;) &gt; tmp2 Compare Object Function Call: comparedf(x = sas_dat1, y = excel_dat1, by = “id”) Shared: 7 non-by variables and 890 observations. Not shared: 14 variables and 0 observations. Differences found in 2/7 variables compared. 8 variables compared have non-identical attributes. &gt; &gt; summary(tmp2) Table 1.1: Summary of data.frames version arg ncol nrow x sas_dat1 15 890 y excel_dat1 15 889 Table 1.1: Summary of overall comparison statistic value Number of by-variables 1 Number of non-by variables in common 7 Number of variables compared 7 Number of variables in x but not y 7 Number of variables in y but not x 7 Number of variables compared with some values unequal 2 Number of variables compared with all values equal 5 Number of observations in common 890 Number of observations in x but not y 0 Number of observations in y but not x 0 Number of observations with some compared variables unequal 890 Number of observations with all compared variables equal 0 Number of values unequal 891 Table 1.1: Variables not shared version variable position class x futime 5 numeric x fustat 6 numeric x alkphos 10 numeric x mdqualitys 12 numeric x ageord 13 character x birthdt 14 Date x resintdt 15 Date y fu.time 5 numeric y fu.stat 6 numeric y alk.phos 10 numeric y mdquality.s 12 numeric y age.ord 13 character y birth.dt 14 character y resint.dt 15 character Table 1.1: Other variables not compared No other variables not compared Table 1.1: Observations not shared No observations not shared Table 1.1: Differences detected by variable var.x var.y n NAs age age 0 0 arm arm 890 0 sex sex 0 0 ps ps 0 0 hgb hgb 0 0 bmi bmi 1 0 ast ast 0 0 Table 1.1: Differences detected (880 not shown) var.x var.y id values.x values.y row.x row.y arm arm 76170 A IFL A: IFL 241 691 arm arm 76240 A IFL A: IFL 72 269 arm arm 76431 A IFL A: IFL 350 175 arm arm 76712 A IFL A: IFL 397 355 arm arm 76780 A IFL A: IFL 645 525 arm arm 77066 A IFL A: IFL 487 216 arm arm 77316 A IFL A: IFL 809 113 arm arm 77355 A IFL A: IFL 678 830 arm arm 77591 A IFL A: IFL 786 217 arm arm 77851 A IFL A: IFL 576 799 bmi bmi 101106 3.059935 30.59935 20 490 Table 1.1: Non-identical attributes var.x var.y name id id format.sas age age format.sas arm arm format.sas arm arm label sex sex format.sas ps ps format.sas ps ps label hgb hgb format.sas hgb hgb label bmi bmi format.sas ast ast format.sas ast ast label One of the big differences appears to be that the Excel data has periods in the variable names whereas the SAS data does not. The following code replaces “.” and substitutes in blanks \"\" to the column names. &gt; ## We could do it ourselves names(excel_dat1) &lt;- make.names(names(excel_dat1), &gt; ## allow_=FALSE) &gt; &gt; ## or we could let comparedf() do it. &gt; summary(comparedf(x = sas_dat1, y = excel_dat1, by = &quot;id&quot;, tol.vars = &quot;.&quot;)) Table: (\\#tab:unnamed-chunk-29)Summary of data.frames version arg ncol nrow -------- ----------- ----- ----- x sas_dat1 15 890 y excel_dat1 15 889 Table: (\\#tab:unnamed-chunk-29)Summary of overall comparison statistic value ------------------------------------------------------------ ------ Number of by-variables 1 Number of non-by variables in common 14 Number of variables compared 12 Number of variables in x but not y 0 Number of variables in y but not x 0 Number of variables compared with some values unequal 2 Number of variables compared with all values equal 10 Number of observations in common 890 Number of observations in x but not y 0 Number of observations in y but not x 0 Number of observations with some compared variables unequal 890 Number of observations with all compared variables equal 0 Number of values unequal 891 Table: (\\#tab:unnamed-chunk-29)Variables not shared | | |:-----------------------| |No variables not shared | Table: (\\#tab:unnamed-chunk-29)Other variables not compared var.x pos.x class.x var.y pos.y class.y --------- ------ -------- ---------- ------ ---------- birthdt 14 Date birth.dt 14 character resintdt 15 Date resint.dt 15 character Table: (\\#tab:unnamed-chunk-29)Observations not shared | | |:--------------------------| |No observations not shared | Table: (\\#tab:unnamed-chunk-29)Differences detected by variable var.x var.y n NAs ----------- ------------ ---- ---- age age 0 0 arm arm 890 0 sex sex 0 0 futime fu.time 0 0 fustat fu.stat 0 0 ps ps 0 0 hgb hgb 0 0 bmi bmi 1 0 alkphos alk.phos 0 0 ast ast 0 0 mdqualitys mdquality.s 0 0 ageord age.ord 0 0 Table: (\\#tab:unnamed-chunk-29)Differences detected (880 not shown) var.x var.y id values.x values.y row.x row.y ------ ------ ------- --------- --------- ------ ------ arm arm 76170 A IFL A: IFL 241 691 arm arm 76240 A IFL A: IFL 72 269 arm arm 76431 A IFL A: IFL 350 175 arm arm 76712 A IFL A: IFL 397 355 arm arm 76780 A IFL A: IFL 645 525 arm arm 77066 A IFL A: IFL 487 216 arm arm 77316 A IFL A: IFL 809 113 arm arm 77355 A IFL A: IFL 678 830 arm arm 77591 A IFL A: IFL 786 217 arm arm 77851 A IFL A: IFL 576 799 bmi bmi 101106 3.059935 30.59935 20 490 Table: (\\#tab:unnamed-chunk-29)Non-identical attributes var.x var.y name ----------- ------------ ----------- id id format.sas age age format.sas arm arm format.sas arm arm label sex sex format.sas futime fu.time format.sas futime fu.time label fustat fu.stat format.sas fustat fu.stat label ps ps format.sas ps ps label hgb hgb format.sas hgb hgb label bmi bmi format.sas alkphos alk.phos format.sas alkphos alk.phos label ast ast format.sas ast ast label mdqualitys mdquality.s format.sas mdqualitys mdquality.s label ageord age.ord format.sas ageord age.ord label birthdt birth.dt class birthdt birth.dt format.sas resintdt resint.dt class resintdt resint.dt format.sas 1.3 Resources 1.3.1 Technical details Report created: September 22 2020 . When asking for help it is often useful to specify which version of R and which version of the packages you are using. &gt; # Grab session info &gt; sessionInfo() R version 3.6.2 (2019-12-12) Platform: x86_64-pc-linux-gnu (64-bit) Running under: CentOS Linux 7 (Core) Matrix products: default BLAS: /usr/lib64/libblas.so.3.4.2 LAPACK: /usr/lib64/liblapack.so.3.4.2 locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=C [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C attached base packages: [1] stats graphics grDevices utils datasets methods base other attached packages: [1] readxl_1.3.1 arsenal_3.4.0.9000 summarytools_0.9.6 knitr_1.29 [5] haven_2.2.0 forcats_0.5.0 stringr_1.4.0 dplyr_1.0.0 [9] purrr_0.3.4 readr_1.3.1 tidyr_1.1.0 tibble_3.0.1 [13] ggplot2_3.3.2 tidyverse_1.3.0 loaded via a namespace (and not attached): [1] httr_1.4.1 jsonlite_1.7.0 splines_3.6.2 modelr_0.1.6 [5] assertthat_0.2.1 highr_0.8 stats4_3.6.2 pander_0.6.4 [9] coin_1.3-1 cellranger_1.1.0 yaml_2.2.1 pillar_1.4.4 [13] backports_1.1.6 lattice_0.20-40 glue_1.4.1 digest_0.6.25 [17] pryr_0.1.4 checkmate_2.0.0 rvest_0.3.5 sandwich_2.5-1 [21] colorspace_1.4-1 htmltools_0.5.0 Matrix_1.2-18 plyr_1.8.6 [25] pkgconfig_2.0.3 broom_0.5.6 magick_2.4.0 bookdown_0.18 [29] mvtnorm_1.1-0 scales_1.1.0 mgcv_1.8-31 farver_2.0.3 [33] generics_0.0.2 ellipsis_0.3.1 TH.data_1.0-10 withr_2.1.2 [37] cli_2.0.2 survival_3.2-5 magrittr_1.5 crayon_1.3.4 [41] evaluate_0.14 fs_1.3.2 fansi_0.4.1 MASS_7.3-51.5 [45] nlme_3.1-145 xml2_1.3.2 rapportools_1.0 tools_3.6.2 [49] hms_0.5.3 multcomp_1.4-12 formatR_1.7 lifecycle_0.2.0 [53] matrixStats_0.56.0 munsell_0.5.0 reprex_0.3.0 compiler_3.6.2 [57] rlang_0.4.7 grid_3.6.2 rstudioapi_0.11 labeling_0.3 [61] tcltk_3.6.2 base64enc_0.1-3 rmarkdown_2.1 gtable_0.3.0 [65] codetools_0.2-16 DBI_1.1.0 R6_2.4.1 zoo_1.8-7 [69] lubridate_1.7.4 libcoin_1.0-5 modeltools_0.2-23 stringi_1.4.6 [73] parallel_3.6.2 Rcpp_1.0.4 vctrs_0.3.2 dbplyr_1.4.2 [77] tidyselect_1.1.0 xfun_0.15 1.3.2 Example of a real program scenario1-regular-program.Rmd 1.3.3 Packages used tidyverse haven dplyr ggplot2 readxl summary tools summarytools with rmarkdown arsenal 1.4 Optional ways to code 1.4.1 Data Import 1.4.1.1 Read in data Here is a slightly fancier way of reading in the data. It pastes together the data directory and the dataset name. Also, instead of first calling library(haven) the code uses the package name (haven) then two colons (::) to indicate the function to be used from within that package. &gt; # Alternative for reading in SAS data - paste together your directory path and &gt; # your dataset name - instead of using library to load the haven package, use the &gt; # package name with two :: to indicate that you want to use the read_sas function &gt; # available in the haven package &gt; &gt; datadir &lt;- &quot;data/&quot; &gt; dat1 &lt;- haven::read_sas(paste0(datadir, &quot;dat1.sas7bdat&quot;)) You can also import SAS data using the sas.get function found in the Hmisc package. As is true with read_sas() it works for most, but not all, SAS datasets. One of the downsides of sas.get() is that you must be working on a system where SAS is installed, whereas read_sas() is based on reverse engineering of the .sas7bdat file format and can be used anywhere. &gt; # Alternative tool for reading in SAS data &gt; library(Hmisc) &gt; &gt; # Note that for sas.get you specify the directory and data file separately &gt; dat1 &lt;- sas.get(libraryName = datadir, member = &quot;dat1&quot;) Although not necessary in this particular example, sometimes you may want to change underscores to dots and upper-case letters to lower-case letters. The function sas.get() automatically does this. &gt; # change the variable names so that underscores are not allowed also change mixed &gt; # case names to all lowercase &gt; &gt; names(sas_dat1) &lt;- tolower(make.names(names(excel_dat1), allow_ = FALSE)) 1.4.1.2 Create dataset with variable labels Sometimes it is helpful to have a dataset containing variable names and labels. &gt; # Grab labels from SAS dataset and create a dataframe of labels These can be used &gt; # for tableby and plotting &gt; &gt; # vlabels &lt;- unlist(sapply(dat1, FUN=function(x) attr(x,&#39;label&#39;))) &gt; vlabels &lt;- unlist(labels(dat1)) &gt; tmp1 &lt;- data.frame(vars = names(vlabels), labels = vlabels) # data for vars with labels &gt; tmp2 &lt;- data.frame(vars = names(dat1)) # data for vars with no existing labels &gt; labeldata &lt;- merge(tmp1, tmp2, all = T, by = &quot;vars&quot;) &gt; &gt; # add in some new labels &gt; &gt; # 1) identify which variables you want to relabel and which column they are in &gt; # Look at what is returned from the match function. &gt; ok &lt;- match(c(&quot;id&quot;, &quot;age&quot;, &quot;sex&quot;, &quot;bmi&quot;, &quot;birthdt&quot;, &quot;resintdt&quot;), labeldata$vars) &gt; &gt; # 2) for those locations, add in new labels &gt; labeldata$labels[ok] &lt;- c(&quot;ID&quot;, &quot;Age&quot;, &quot;Sex&quot;, &quot;BMI&quot;, &quot;Birthdate&quot;, &quot;ResInt Date&quot;) &gt; &gt; # These next two lines create a list called vlabels and sets things up so that &gt; # the variable labels can be accessed by their variable names. For example &gt; # vlabels$birthdt or vlabels[[&#39;birthdt&#39;]] will return &#39;Birthdate&#39; &gt; vlabels &lt;- as.list(labeldata$labels) &gt; names(vlabels) &lt;- labeldata$vars &gt; &gt; # Remove some attributes from variables in data frame - when applied in a loop &gt; # like this you need to use attr(dat1[[vname]]) instead of attr(dat1[,vname]) &gt; for (vname in names(dat1)) { + attr(dat1[[vname]], &quot;format.sas&quot;) &lt;- NULL + } 1.4.1.3 Tibble versus data.frame objects To see what type of object the function read_sas creates, we can use the class function. &gt; class(dat1) [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; Here we see that the function returns 3 values. data.frame indicates that dat1 is a data frame. tbl_df and tbl indicates that dat1 is a tibble which is essentially just a fancy data.frame. Because these are listed first, functionality related to those classes will be used first. Some people like the tibble default and others do not. If you want to remove the tibble class, you can do the following using as.data.frame(). Try some of the exercises using dat1 versus dat1b to see how they differ. &gt; # Create dataframe instead of tibble &gt; dat1b &lt;- as.data.frame(dat1) &gt; class(dat1b) [1] &quot;data.frame&quot; &gt; &gt; # Alternatives for viewing the data &gt; dat1 # A tibble: 890 x 15 id age arm sex futime fustat ps hgb bmi alkphos ast &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 84681 57 F FO… Male 799 2 0 11.2 NA 102 7 2 89253 64 F FO… Fema… 97 2 1 12.6 NA 272 62 3 89499 75 F FO… Fema… 105 2 1 12.5 NA 169 23 4 90166 54 G IR… Fema… 878 2 0 10.9 NA 247 23 5 90291 71 A IFL Male 31 2 2 9.1 NA 304 115 6 91450 71 F FO… Fema… 1046 1 NA NA NA NA NA 7 91486 66 A IFL Male 60 2 1 10.5 NA 196 39 8 91504 56 A IFL Male 181 2 1 10.8 NA 252 77 9 91724 50 G IR… Male 481 2 1 13.4 NA 69 13 10 92079 43 A IFL Male 149 2 NA NA NA NA NA # … with 880 more rows, and 4 more variables: mdqualitys &lt;dbl&gt;, ageord &lt;chr&gt;, # birthdt &lt;date&gt;, resintdt &lt;date&gt; &gt; dat1b id age arm sex futime fustat ps hgb bmi alkphos ast 1 84681 57 F FOLFOX Male 799 2 0 11.2 NA 102 7 2 89253 64 F FOLFOX Female 97 2 1 12.6 NA 272 62 3 89499 75 F FOLFOX Female 105 2 1 12.5 NA 169 23 4 90166 54 G IROX Female 878 2 0 10.9 NA 247 23 5 90291 71 A IFL Male 31 2 2 9.1 NA 304 115 6 91450 71 F FOLFOX Female 1046 1 NA NA NA NA NA 7 91486 66 A IFL Male 60 2 1 10.5 NA 196 39 8 91504 56 A IFL Male 181 2 1 10.8 NA 252 77 9 91724 50 G IROX Male 481 2 1 13.4 NA 69 13 10 92079 43 A IFL Male 149 2 NA NA NA NA NA 11 92420 51 F FOLFOX Female 728 2 0 10.9 NA 126 25 12 92445 51 G IROX Male 751 2 1 12.4 NA 302 51 13 92587 77 F FOLFOX Male 260 2 1 14.2 NA 190 20 14 92769 48 F FOLFOX Male 114 2 0 12.0 NA 93 45 15 92886 47 A IFL Female 355 2 0 11.0 NA 106 74 16 92965 68 F FOLFOX Male 47 2 0 14.2 NA 80 16 17 93976 63 G IROX Male 28 2 1 12.3 NA 180 33 18 99485 69 F FOLFOX Male 742 2 1 13.2 NA 184 36 19 105271 50 A IFL Female 175 2 1 11.1 NA 700 100 20 101106 79 F FOLFOX Female 865 2 0 13.7 3.059935 74 42 21 79795 74 A IFL Male 462 2 0 12.8 14.053002 103 28 22 92121 64 G IROX Female 824 2 2 11.6 16.071361 72 19 23 85064 59 F FOLFOX Female 549 2 0 15.6 16.649324 73 27 24 92581 56 G IROX Female 205 2 2 14.7 16.842653 118 34 25 92115 35 A IFL Female 636 2 1 15.2 17.345679 240 28 26 91647 38 G IROX Male 97 2 2 10.3 17.376543 197 23 27 93491 53 G IROX Female 682 2 0 13.1 17.614513 437 104 28 101512 57 G IROX Female 659 2 0 11.6 17.741047 153 17 29 92030 38 G IROX Male 1445 2 0 15.2 17.751479 105 24 30 92054 47 F FOLFOX Female 1946 1 NA NA 18.069728 NA NA 31 93374 61 F FOLFOX Female 1976 1 NA NA 18.106073 NA NA 32 101202 41 G IROX Female 282 2 0 12.4 18.181818 362 49 33 93165 70 G IROX Female 626 2 0 10.4 18.306361 405 31 mdqualitys ageord birthdt resintdt 1 NA 50-59 2007-03-01 1997-01-01 2 1 60-69 1850-01-01 1997-01-01 3 1 70-79 1921-01-01 2012-06-19 4 1 50-59 1850-01-01 1997-01-01 5 1 70-79 1911-11-11 1997-01-01 6 1 70-79 1960-01-01 &lt;NA&gt; 7 0 60-69 1985-11-07 2012-12-20 8 1 50-59 1966-04-10 1997-01-01 9 NA 40-49 1929-07-04 1996-12-31 10 0 40-49 2004-07-01 1997-01-01 11 0 50-59 1939-05-17 1997-01-01 12 NA 50-59 2004-03-31 1997-01-01 13 1 70-79 1929-03-23 &lt;NA&gt; 14 NA 40-49 2005-08-01 1997-01-01 15 1 40-49 1971-05-08 1997-01-01 16 NA 60-69 2005-10-01 1997-01-01 17 NA 60-69 1940-09-20 2012-12-20 18 1 60-69 1969-12-31 1997-01-01 19 1 40-49 1850-01-01 1997-01-01 20 NA 70-79 1955-05-05 1996-12-31 21 1 70-79 1975-05-05 1997-01-01 22 0 60-69 1961-11-09 2002-08-20 23 NA 50-59 1974-04-04 &lt;NA&gt; 24 0 50-59 1950-01-01 1997-01-01 25 0 30-39 1963-01-01 1997-01-01 26 0 30-39 1899-09-13 1997-01-01 27 1 50-59 2000-12-12 1997-01-01 28 1 50-59 1920-01-01 1997-01-01 29 1 30-39 1919-09-20 1997-01-01 30 1 40-49 1968-12-31 1997-01-01 31 1 60-69 1922-08-06 2012-12-20 32 NA 40-49 1960-10-10 1997-01-01 33 1 60-69 1961-07-29 1997-01-01 [ reached &#39;max&#39; / getOption(&quot;max.print&quot;) -- omitted 857 rows ] &gt; &gt; # look at the beginning and end of the data &gt; head(dat1) # A tibble: 6 x 15 id age arm sex futime fustat ps hgb bmi alkphos ast &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 84681 57 F FO… Male 799 2 0 11.2 NA 102 7 2 89253 64 F FO… Fema… 97 2 1 12.6 NA 272 62 3 89499 75 F FO… Fema… 105 2 1 12.5 NA 169 23 4 90166 54 G IR… Fema… 878 2 0 10.9 NA 247 23 5 90291 71 A IFL Male 31 2 2 9.1 NA 304 115 6 91450 71 F FO… Fema… 1046 1 NA NA NA NA NA # … with 4 more variables: mdqualitys &lt;dbl&gt;, ageord &lt;chr&gt;, birthdt &lt;date&gt;, # resintdt &lt;date&gt; &gt; head(dat1b) id age arm sex futime fustat ps hgb bmi alkphos ast mdqualitys 1 84681 57 F FOLFOX Male 799 2 0 11.2 NA 102 7 NA 2 89253 64 F FOLFOX Female 97 2 1 12.6 NA 272 62 1 3 89499 75 F FOLFOX Female 105 2 1 12.5 NA 169 23 1 4 90166 54 G IROX Female 878 2 0 10.9 NA 247 23 1 5 90291 71 A IFL Male 31 2 2 9.1 NA 304 115 1 6 91450 71 F FOLFOX Female 1046 1 NA NA NA NA NA 1 ageord birthdt resintdt 1 50-59 2007-03-01 1997-01-01 2 60-69 1850-01-01 1997-01-01 3 70-79 1921-01-01 2012-06-19 4 50-59 1850-01-01 1997-01-01 5 70-79 1911-11-11 1997-01-01 6 70-79 1960-01-01 &lt;NA&gt; &gt; tail(dat1b) id age arm sex futime fustat ps hgb bmi alkphos ast 885 89665 64 F FOLFOX Male 1097 2 NA NA 47.45809 NA NA 886 92645 71 A IFL Male 1948 1 0 13.4 48.38404 56 25 887 94378 69 F FOLFOX Female 992 2 1 10.9 49.12978 499 66 888 95155 50 G IROX Male 752 2 1 14.4 51.32413 89 31 889 91494 38 A IFL Female 412 2 1 10.1 53.00776 94 178 890 91923 51 G IROX Male 51 2 1 11.9 60.24257 163 58 mdqualitys ageord birthdt resintdt 885 1 60-69 1972-02-02 1997-01-01 886 1 70-79 1968-05-05 2012-11-21 887 NA 60-69 1942-04-03 2012-12-20 888 NA 40-49 1970-07-16 1997-01-01 889 1 30-39 1972-06-02 1997-01-01 890 0 50-59 1949-12-31 1997-01-01 &gt; &gt; # What differs when you use dat1 and dat1b? Which do you like better? 1.4.2 Data Exploring Take a closer look at the data using basic summary statistics. Do you notice any strange values? If so, fix them. We can change the variable types using the dplyr package and mutate_at(). We will not include id in the tables since they are unique identifiers. The code shown below makes all of these variables factors instead of numeric variables. &gt; library(dplyr) &gt; cols &lt;- vars(&quot;id&quot;, &quot;fustat&quot;, &quot;ps&quot;, &quot;mdqualitys&quot;) &gt; new_dat &lt;- dat1 %&gt;% mutate_at(cols, ~factor(.)) Here is another use of tableby to explore the data, removing the variable id on-the-fly using the select() function. &gt; summary(tableby(~., data = subset(dat1, select = -id)), title = &quot;Baseline and patient characteristics&quot;) Baseline and patient characteristics Overall (N=890) age    Mean (SD) 60.152 (11.342)    Range 27.000 - 88.000 Treatment Arm    A IFL 303 (34.0%)    F FOLFOX 299 (33.6%)    G IROX 288 (32.4%) sex    2 2 (0.2%)    F 2 (0.2%)    Female 347 (39.0%)    Male 539 (60.6%) Follow-up Time    Mean (SD) 635.284 (487.802)    Range 9.000 - 2472.000 Follow-up Status    Mean (SD) 1.924 (0.266)    Range 1.000 - 2.000 ECOG Performance Score    N-Miss 120    Mean (SD) 0.532 (0.601)    Range 0.000 - 2.000 Hemoglobin Count    N-Miss 120    Mean (SD) 12.359 (1.698)    Range 9.000 - 18.200 bmi    N-Miss 19    Mean (SD) 27.106 (5.620)    Range 3.060 - 60.243 Alkaline Phosphotase    N-Miss 120    Mean (SD) 173.832 (135.659)    Range 7.000 - 1014.000 Aspartate Transaminase    N-Miss 120    Mean (SD) 36.465 (27.148)    Range 7.000 - 205.000 LASA QOL    N-Miss 98    Mean (SD) 0.893 (0.310)    Range 0.000 - 1.000 Age Category    20-29 12 (1.3%)    30-39 40 (4.5%)    40-49 117 (13.1%)    50-59 256 (28.8%)    60-69 288 (32.4%)    70-79 162 (18.2%)    80-89 15 (1.7%) birthdt    Median 1966-09-22    Range 1850-01-01 - 2015-04-06 resintdt    N-Miss 78    Median 1997-01-01    Range 1996-12-31 - 2014-02-19 How many missing values are there? Here are a couple of ways to explore this looking at missingness by subject and by variable. The key to both approaches is to use the is.na() function which returns a logical (T/F) depending on whether there is a missing value in a given position. First, use a dplyr approach. The summarize_all() function is handy in that it says do “this” to each variable. Here, the “this” says apply is.na(), then take the mean value, multiply that by 100, and round the result so that there are 2 decimal points. Take all these new values and make them into a data frame. &gt; # Look at the missing rates for each variable using a dplyr approach &gt; library(dplyr) &gt; dat1 %&gt;% summarize_all(funs(round(100 * mean(is.na(.)), 2))) %&gt;% as.data.frame Warning: `funs()` is deprecated as of dplyr 0.8.0. Please use a list of either functions or lambdas: # Simple named list: list(mean = mean, median = median) # Auto named with `tibble::lst()`: tibble::lst(mean, median) # Using lambdas list(~ mean(., trim = .2), ~ median(., na.rm = TRUE)) This warning is displayed once every 8 hours. Call `lifecycle::last_warnings()` to see where this warning was generated. id age arm sex futime fustat ps hgb bmi alkphos ast mdqualitys ageord 1 0 0 0 0 0 0 13.48 13.48 2.13 13.48 13.48 11.01 0 birthdt resintdt 1 0 8.76 This is a base R approach using the function colMeans(). In this approach, is.na() is applied to the whole dataset resulting in a dataframe of T/F. For each column, take the mean using colMeans, then multiply by 100 and round the results. This same logic is then used looking at the rows instead of the columns to look at the missing rates for each subject. &gt; # Create a dataset with T/F indicating if there is a missing value Take the mean &gt; # of each column &gt; round(100 * colMeans(is.na(dat1)), 2) id age arm sex futime fustat ps 0.00 0.00 0.00 0.00 0.00 0.00 13.48 hgb bmi alkphos ast mdqualitys ageord birthdt 13.48 2.13 13.48 13.48 11.01 0.00 0.00 resintdt 8.76 &gt; &gt; # Look at the missing rates for each subject &gt; tmp &lt;- round(100 * rowMeans(is.na(dat1)), 2) &gt; summary(tmp) Min. 1st Qu. Median Mean 3rd Qu. Max. 0.000 0.000 0.000 5.057 6.670 40.000 &gt; &gt; # percentage of subjects missing at least 25% of variables &gt; 100 * mean(tmp &gt;= 25) [1] 13.48315 We want to look at the data by gender. But wait, the variable “sex” needs to be cleaned up. There are a few ways to do this, gsub, ifelse, case_when, others? Here is how to do it with case_when(), another function available in the dplyr package. &gt; library(dplyr) &gt; &gt; dat1$sex &lt;- case_when(dat1$sex == 2 ~ &quot;Female&quot;, dat1$sex == &quot;F&quot; ~ &quot;Female&quot;, TRUE ~ + dat1$sex) &gt; &gt; table(dat1$sex) Female Male 351 539 Here is another solution for cleaning up variables using the forcats package. &gt; # Fix gender coding issues, not necessary to access entire forcats library &gt; dat1$sex &lt;- forcats::fct_collapse(dat1$sex, Male = c(&quot;Male&quot;, &quot;2&quot;), Female = c(&quot;Female&quot;, + &quot;F&quot;)) Warning: Unknown levels in `f`: 2, F And yet another solution using fct_collapse() and mutate(). &gt; library(forcats) &gt; &gt; # Fix gender levels and convert arm, sex and ageord to factor &gt; df_clean &lt;- dat1 %&gt;% mutate(arm = factor(arm), sex = fct_collapse(fct_inorder(sex), + Male = &quot;Male&quot;, Female = c(&quot;F&quot;, &quot;Female&quot;)), ageord = factor(ageord)) %&gt;% filter(sex != + &quot;2&quot;) %&gt;% # We don&#39;t know for certain if 2 is M or F - filter for now and check source / + # codebook + droplevels() Warning: Unknown levels in `f`: F &gt; # Fix some factor variables currently treated as numeric Mutate is from the &gt; # &#39;dplyr&#39; library &gt; dat1 &lt;- mutate(dat1, ps = factor(ps, levels = 0:2, labels = c(&quot;PS=0&quot;, &quot;PS=1&quot;, &quot;PS=2&quot;)), + mdqualitys = factor(mdqualitys, levels = 0:1, labels = c(&quot;No&quot;, &quot;Yes&quot;)), fustat = factor(fustat, + levels = 1:2, labels = c(&quot;Event&quot;, &quot;Censor&quot;))) Oops, there is a duplicate observation in the data. Confirm the data is the same for all the variables and remove one of the duplicates. Here is a fancy table showing which line in the data is completely duplicated, however this won’t work if some of the variables are duplicated and some are not. &gt; kable(dat1[duplicated(dat1), ] %&gt;% select(&quot;id&quot;, &quot;age&quot;, &quot;arm&quot;, &quot;sex&quot;, &quot;bmi&quot;), caption = &quot;Duplicate Records&quot;) Table 1.2: Duplicate Records id age arm sex bmi Here is another option for creating a version of the dataset without duplicates using the dplyr package. &gt; # Remove exact duplicates &gt; dat2 &lt;- dplyr::distinct(dat1) &gt; dim(dat2) [1] 890 15 Do the summary statistics make sense for each variable? If not, modify them so that the default summaries fit the data. Here is some code to assign labels to variables so that they are more presentable in tables using labels() and upData() from the Hmisc package. &gt; library(Hmisc) Loading required package: lattice Loading required package: survival Loading required package: Formula Attaching package: &#39;Hmisc&#39; The following object is masked from &#39;package:arsenal&#39;: %nin% The following objects are masked from &#39;package:summarytools&#39;: label, label&lt;- The following objects are masked from &#39;package:dplyr&#39;: src, summarize The following objects are masked from &#39;package:base&#39;: format.pval, units &gt; new_dat &lt;- dat1 %&gt;% upData(labels = unlist(labels(dat1))) Input object size: 99976 bytes; 15 variables 890 observations New object size: 83968 bytes; 15 variables 890 observations &gt; label(new_dat$bmi) &lt;- &quot;Body Mass Index&quot; Fancier: create a formula from a list of variables that can used in tableby (hint: formulize) &gt; # Default report I&#39;m going to use the same formula many times, so let&#39;s define it &gt; # once LHS=Arm, RHS=all other variables except id exclude RHS identifies &gt; # variables to leave out from right hand side (as indices) &gt; excludeRHS &lt;- which(names(dat1) %in% c(&quot;id&quot;, &quot;arm&quot;)) &gt; tableformula &lt;- formulize(y = &quot;arm&quot;, x = names(dat1[, -excludeRHS])) &gt; t1 &lt;- tableby(tableformula, data = dat1, total = FALSE) &gt; summary(t1) A IFL (N=303) F FOLFOX (N=299) G IROX (N=288) p value age 0.585    Mean (SD) 59.696 (11.365) 60.652 (11.422) 60.111 (11.253)    Range 27.000 - 88.000 27.000 - 88.000 28.000 - 84.000 sex 0.175    Female 107 (35.3%) 127 (42.5%) 117 (40.6%)    Male 196 (64.7%) 172 (57.5%) 171 (59.4%) Follow-up Time &lt; 0.001    Mean (SD) 528.201 (411.359) 760.264 (555.458) 618.191 (458.231)    Range 9.000 - 2170.000 19.000 - 2472.000 17.000 - 2118.000 fustat &lt; 0.001    Event 10 (3.3%) 36 (12.0%) 22 (7.6%)    Censor 293 (96.7%) 263 (88.0%) 266 (92.4%) ps 0.956    N-Miss 45 39 36    PS=0 140 (54.3%) 134 (51.5%) 129 (51.2%)    PS=1 104 (40.3%) 112 (43.1%) 108 (42.9%)    PS=2 14 (5.4%) 14 (5.4%) 15 (6.0%) Hemoglobin Count 0.213    N-Miss 45 39 36    Mean (SD) 12.232 (1.653) 12.494 (1.760) 12.350 (1.674)    Range 9.060 - 17.300 9.070 - 18.200 9.000 - 17.000 bmi 0.745    N-Miss 6 9 4    Mean (SD) 27.278 (5.493) 27.112 (5.499) 26.920 (5.883)    Range 14.053 - 53.008 3.060 - 49.130 16.071 - 60.243 Alkaline Phosphotase 0.707    N-Miss 45 39 36    Mean (SD) 170.612 (124.842) 171.377 (133.671) 179.663 (148.110)    Range 13.000 - 858.000 18.000 - 1014.000 7.000 - 982.000 Aspartate Transaminase 0.903    N-Miss 45 39 36    Mean (SD) 36.310 (26.455) 37.062 (28.716) 36.008 (26.266)    Range 11.000 - 205.000 7.000 - 174.000 10.000 - 176.000 mdqualitys 0.936    N-Miss 31 35 32    No 30 (11.0%) 29 (11.0%) 26 (10.2%)    Yes 242 (89.0%) 235 (89.0%) 230 (89.8%) Age Category 0.994    20-29 3 (1.0%) 4 (1.3%) 5 (1.7%)    30-39 15 (5.0%) 12 (4.0%) 13 (4.5%)    40-49 46 (15.2%) 36 (12.0%) 35 (12.2%)    50-59 85 (28.1%) 89 (29.8%) 82 (28.5%)    60-69 98 (32.3%) 96 (32.1%) 94 (32.6%)    70-79 52 (17.2%) 56 (18.7%) 54 (18.8%)    80-89 4 (1.3%) 6 (2.0%) 5 (1.7%) birthdt 0.653    Median 1966-10-09 1969-01-01 1964-10-02    Range 1850-01-01 - 2015-04-06 1850-01-01 - 2013-11-03 1850-01-01 - 2014-01-01 resintdt 0.807    N-Miss 18 37 23    Median 1997-01-01 1997-01-01 1997-01-01    Range 1996-12-31 - 2014-02-19 1996-12-31 - 2013-11-01 1996-12-31 - 2013-12-17 Instead of using formulize() you can paste together your own formula. &gt; var &lt;- c(&quot;futime&quot;, &quot;fustat&quot;, &quot;ps&quot;, &quot;hgb&quot;, &quot;bmi&quot;) &gt; select_few &lt;- paste(var, collapse = &quot;+&quot;) &gt; summary(tableby(as.formula(paste(&quot;arm ~ &quot;, select_few)), data = dat2), title = &quot;Baseline and patient characteristics by Treatment Arm&quot;) Baseline and patient characteristics by Treatment Arm A IFL (N=303) F FOLFOX (N=299) G IROX (N=288) Total (N=890) p value Follow-up Time &lt; 0.001    Mean (SD) 528.201 (411.359) 760.264 (555.458) 618.191 (458.231) 635.284 (487.802)    Range 9.000 - 2170.000 19.000 - 2472.000 17.000 - 2118.000 9.000 - 2472.000 fustat &lt; 0.001    Event 10 (3.3%) 36 (12.0%) 22 (7.6%) 68 (7.6%)    Censor 293 (96.7%) 263 (88.0%) 266 (92.4%) 822 (92.4%) ps 0.956    N-Miss 45 39 36 120    PS=0 140 (54.3%) 134 (51.5%) 129 (51.2%) 403 (52.3%)    PS=1 104 (40.3%) 112 (43.1%) 108 (42.9%) 324 (42.1%)    PS=2 14 (5.4%) 14 (5.4%) 15 (6.0%) 43 (5.6%) Hemoglobin Count 0.213    N-Miss 45 39 36 120    Mean (SD) 12.232 (1.653) 12.494 (1.760) 12.350 (1.674) 12.359 (1.698)    Range 9.060 - 17.300 9.070 - 18.200 9.000 - 17.000 9.000 - 18.200 bmi 0.745    N-Miss 6 9 4 19    Mean (SD) 27.278 (5.493) 27.112 (5.499) 26.920 (5.883) 27.106 (5.620)    Range 14.053 - 53.008 3.060 - 49.130 16.071 - 60.243 3.060 - 60.243 1.4.3 Plotting Here are some alternatives for creating the boxplots using ggplot. &gt; dat2 %&gt;% ggplot(aes(x = factor(0), y = bmi)) + geom_boxplot() + scale_x_discrete(breaks = NULL) + + xlab(NULL) Warning: Removed 19 rows containing non-finite values (stat_boxplot). &gt; &gt; ## geom_boxplot for boxplots by categorical &gt; dat2 %&gt;% ggplot(aes(x = arm, y = bmi)) + geom_boxplot() + labs(x = &quot;Treatment Arm&quot;, + y = &quot;Age at Diagnosis&quot;, title = &quot;Age with Treatment Group&quot;, subtitle = &quot;This is a subtitle&quot;, + caption = &quot;This is a caption&quot;) Warning: Removed 19 rows containing non-finite values (stat_boxplot). &gt; &gt; # this shows a different coloring scheme (theme_bw) &gt; ggplot(dat2, aes(y = bmi, x = arm)) + geom_boxplot(fill = &quot;aliceblue&quot;) + theme_bw() + + ggtitle(&quot;Boxplot of BMI by treatment arm&quot;) + scale_y_continuous(name = &quot;BMI&quot;, + breaks = seq(0, 70, 10), limits = c(0, 70)) + scale_x_discrete(name = &quot;Treatment Arm&quot;) + + theme(panel.grid.major = element_line(colour = &quot;#e8e5e5&quot;), panel.grid.minor = element_blank(), + panel.border = element_blank(), panel.background = element_blank(), plot.title = element_text(size = 14, + face = &quot;bold&quot;), axis.title = element_text(face = &quot;bold&quot;), axis.text.x = element_text(colour = &quot;black&quot;, + size = 11), axis.text.y = element_text(colour = &quot;black&quot;, size = 9), axis.line = element_line(size = 0.3, + colour = &quot;black&quot;)) Warning: Removed 19 rows containing non-finite values (stat_boxplot). Now make two scatterplots side-by-side, split by sex In addition to facet_grid() and facet_wrap() there is the grid.arrange() function which allows you to plot multiple figures on one page. &gt; library(gridExtra) Attaching package: &#39;gridExtra&#39; The following object is masked from &#39;package:dplyr&#39;: combine &gt; &gt; plot1 &lt;- ggplot(filter(dat2, sex == &quot;Female&quot;), aes(x = age, y = bmi, color = arm)) + + geom_point() + ggtitle(&quot;Female Scatter Plot&quot;) &gt; plot2 &lt;- ggplot(filter(dat2, sex == &quot;Male&quot;), aes(x = age, y = bmi, color = arm)) + + geom_point() + ggtitle(&quot;Male Scatter Plot&quot;) &gt; &gt; grid.arrange(plot1, plot2, ncol = 2) Warning: Removed 7 rows containing missing values (geom_point). Warning: Removed 12 rows containing missing values (geom_point). &gt; ggplot(dat2, aes(x = age, y = bmi)) + geom_point() + theme_bw() + theme() + ggtitle(&quot;Scatterplot - Age by BMI&quot;) + + labs(x = vlabels$age, y = vlabels$bmi) + facet_grid(. ~ sex) Warning: Removed 19 rows containing missing values (geom_point). Fancier: How would you add a regression line to these plots? How about smoothers? There are other packages that can do some of this work, but essentially this is how you would create these plots using base R graphics. &gt; # code using basic R -- Regression lines &gt; par(mfrow = c(1, 2)) &gt; plot(bmi ~ age, data = dat2[dat2$sex == &quot;Female&quot;, ], col = as.numeric(as.factor(arm)), + main = &quot;Females&quot;) &gt; abline(lm(bmi ~ age, data = dat2[dat2$sex == &quot;Female&quot; &amp; dat2$arm == &quot;A IFL&quot;, ]), + col = 1) &gt; abline(lm(bmi ~ age, data = dat2[dat2$sex == &quot;Female&quot; &amp; dat2$arm == &quot;F FOLFOX&quot;, ]), + col = 2) &gt; abline(lm(bmi ~ age, data = dat2[dat2$sex == &quot;Female&quot; &amp; dat2$arm == &quot;G IROX&quot;, ]), + col = 3) &gt; &gt; plot(bmi ~ age, data = dat2[dat2$sex == &quot;Male&quot;, ], col = as.numeric(as.factor(arm)), + main = &quot;Males&quot;) &gt; abline(lm(bmi ~ age, data = dat2[dat2$sex == &quot;Male&quot; &amp; dat2$arm == &quot;A IFL&quot;, ]), col = 1) &gt; abline(lm(bmi ~ age, data = dat2[dat2$sex == &quot;Male&quot; &amp; dat2$arm == &quot;F FOLFOX&quot;, ]), + col = 2) &gt; abline(lm(bmi ~ age, data = dat2[dat2$sex == &quot;Male&quot; &amp; dat2$arm == &quot;G IROX&quot;, ]), col = 3) &gt; legend(&quot;topright&quot;, legend = c(&quot;A IFL&quot;, &quot;F FOLFOX&quot;, &quot;G IROX&quot;), col = 1:3, lty = 1, + bty = &quot;n&quot;) &gt; par(mfrow = c(1, 1)) &gt; &gt; # -- Smoothers &gt; par(mfrow = c(1, 2)) &gt; # females &gt; plot(bmi ~ age, data = dat2[dat2$sex == &quot;Female&quot;, ], col = as.numeric(as.factor(arm)), + main = &quot;Females&quot;) &gt; tmp &lt;- na.omit(dat2[which(dat2$sex == &quot;Female&quot; &amp; dat2$arm == &quot;A IFL&quot;), c(&quot;bmi&quot;, &quot;age&quot;)]) &gt; lines(with(tmp, smooth.spline(bmi ~ age, spar = 0.8)), col = 1, lwd = 2) &gt; &gt; tmp &lt;- na.omit(dat2[which(dat2$sex == &quot;Female&quot; &amp; dat2$arm == &quot;F FOLFOX&quot;), c(&quot;bmi&quot;, + &quot;age&quot;)]) &gt; lines(with(tmp, smooth.spline(bmi ~ age, spar = 0.8)), col = 2, lwd = 2) &gt; tmp &lt;- na.omit(dat2[which(dat2$sex == &quot;Female&quot; &amp; dat2$arm == &quot;G IROX&quot;), c(&quot;bmi&quot;, + &quot;age&quot;)]) &gt; lines(with(tmp, smooth.spline(bmi ~ age, spar = 0.8)), col = 3, lwd = 2) &gt; &gt; # males &gt; plot(bmi ~ age, data = dat2[dat2$sex == &quot;Male&quot;, ], col = as.numeric(as.factor(arm)), + main = &quot;Males&quot;) &gt; tmp &lt;- na.omit(dat2[which(dat2$sex == &quot;Male&quot; &amp; dat2$arm == &quot;A IFL&quot;), c(&quot;bmi&quot;, &quot;age&quot;)]) &gt; lines(with(tmp, smooth.spline(bmi ~ age, spar = 0.8)), col = 1, lwd = 2) &gt; &gt; tmp &lt;- na.omit(dat2[which(dat2$sex == &quot;Male&quot; &amp; dat2$arm == &quot;F FOLFOX&quot;), c(&quot;bmi&quot;, + &quot;age&quot;)]) &gt; lines(with(tmp, smooth.spline(bmi ~ age, spar = 0.8)), col = 2, lwd = 2) &gt; tmp &lt;- na.omit(dat2[which(dat2$sex == &quot;Male&quot; &amp; dat2$arm == &quot;G IROX&quot;), c(&quot;bmi&quot;, &quot;age&quot;)]) &gt; lines(with(tmp, smooth.spline(bmi ~ age, spar = 0.8)), col = 3, lwd = 2) &gt; &gt; # legend &gt; legend(&quot;topright&quot;, legend = c(&quot;A IFL&quot;, &quot;F FOLFOX&quot;, &quot;G IROX&quot;), col = 1:3, lty = 1, + bty = &quot;n&quot;) &gt; par(mfrow = c(1, 1)) 1.4.4 Basic Modeling There is a lot of information stored in a model object and broom doesn’t work for all types of models. Sometimes you need to save the results from the summary of a fit which gives you different information than the fit itself. &gt; # What is stored in the lm object? &gt; names(fit1) [1] &quot;coefficients&quot; &quot;residuals&quot; &quot;effects&quot; &quot;rank&quot; [5] &quot;fitted.values&quot; &quot;assign&quot; &quot;qr&quot; &quot;df.residual&quot; [9] &quot;na.action&quot; &quot;xlevels&quot; &quot;call&quot; &quot;terms&quot; [13] &quot;model&quot; &gt; &gt; # Now create a summary.lm object and see what is stored there &gt; tmp &lt;- summary(fit1) &gt; names(tmp) [1] &quot;call&quot; &quot;terms&quot; &quot;residuals&quot; &quot;coefficients&quot; [5] &quot;aliased&quot; &quot;sigma&quot; &quot;df&quot; &quot;r.squared&quot; [9] &quot;adj.r.squared&quot; &quot;fstatistic&quot; &quot;cov.unscaled&quot; &quot;na.action&quot; &gt; &gt; # Look at the model coefficients and p-values &gt; tmp$coefficients Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 25.6960705 0.6521116 39.404408 1.354488e-195 sex12 0.8783982 0.3886608 2.260064 2.406410e-02 &gt; class(tmp$coefficients) [1] &quot;matrix&quot; 1.4.5 Data Import, revisited There are other packages that also read in Excel data including openxlsx and gdata. The package xlsx causes problems within RStudio and so users are strongly encouraged to no longer use that particular package. Note that openxlsx will only open newer .xlsx files. All three functions have slightly different options so if you need to do something fancy with Excel, it is worth looking more closely at the help pages. &gt; # gdata &gt; v1 &lt;- gdata::read.xls(xls = &quot;data/dat1.xls&quot;, sheet = 1) &gt; &gt; # readxl &gt; v2 &lt;- readxl::read_excel(path = &quot;data/dat1.xls&quot;, sheet = 1) &gt; &gt; # openxlsx, cannot real .xls - only .xlsx v3 &lt;- &gt; # openxlsx::read.xlsx(xlsxFile=&#39;data/dat1.xls&#39;, sheet=1) One of the differences between reading in SAS and Excel is that Excel doesn’t have the concept of variable labels. &gt; # Does the excel file have any variable labels? &gt; head(labels(excel_dat1)) $id NULL $age NULL $arm NULL $sex NULL $fu.time NULL $fu.stat NULL &gt; &gt; head(labels(sas_dat1)) $id NULL $age NULL $arm [1] &quot;Treatment Arm&quot; $sex NULL $fu.time [1] &quot;Follow-up Time&quot; $fu.stat [1] &quot;Follow-up Status&quot; "],
["scenario-2-in-depth-modeling-and-plotting-with-cleaned-data.html", "2 Scenario 2: In Depth Modeling and Plotting with Cleaned Data 2.1 Your Mission 2.2 Implementation 2.3 Resources 2.4 Optional ways to code", " 2 Scenario 2: In Depth Modeling and Plotting with Cleaned Data You are working on a project and have cleaned the data using SAS but you would like to create a summary report using R markdown. The study has eleven covariates and three endpoints: discharge status (alive/deceased), time-to-tvr (tricuspid valve replacement), and time-to-death. The investigator is interested in understanding the relationship of the covariates with the different endpoints. Note that some of the covariates have missing values. Also, the investigator would like to see a figure showing the cumulative incidence of TVR curve. 2.1 Your Mission Read in dataset “data2.sas7bdat”. This data was cleaned and labelled in SAS, but you may need to modify some of the variables slightly so that they produce the right summaries. For instance, a number of the variables have the SAS format where 1=‘No’ and 2=‘Yes’. The variable recentmi has four levels: &lt;24 hrs, 1-7 days, &gt;7 days, never. Explore the data and modify the variables as you see fit. Create a list of the variable labels for use in summaries. Investigate the missing data patterns. This could be graphically or with tables. Create a Kaplan-Meier curve of death for subjects by gender Create a time to death variable (difference between dates). Look at a summary of this new variable. Create a cumulative incidence curve of TVR where death is treated as a competing risk. Steps include: Create a time-to-tvr variable Stratify the curves by gender Run a linear regression model for bmi with the covariates age and sex. Check the modeling assumptions. Run logistic models for dischargestatus and create summary tables for each covariate. Investigate the modelsum() function in the arsenal package and tidy() in the broom package. Run Cox models for tm2lfu and create summary tables for each covariate. write results to a separate file check model assumptions Perform multiple imputation and rerun the logistic regression models 2.2 Implementation 2.2.1 Read and summarize data &gt; # Strongly encouraged to set this option! &gt; options(stringsAsFactors = F) &gt; &gt; # Include tidyverse and arsenal to have some basic packages &gt; library(tidyverse) &gt; library(arsenal) &gt; &gt; # Read in data &gt; library(haven) &gt; &gt; # link to data on GitHub page if not already downloaded &gt; if (!file.exists(&quot;data/dat1.sas7bdat&quot;)) { + urlfile &lt;- &quot;https://raw.githubusercontent.com/bethatkinson/R_project_recipes/data/dat1.sas7bdat&quot; + if (!dir.exists(&quot;data&quot;)) + dir.create(&quot;data&quot;) + download.file(urlfile, destfile = &quot;data/dat1.sas7bdat&quot;) + } &gt; &gt; d1 &lt;- read_sas(&quot;data/data2.sas7bdat&quot;) &gt; names(d1) [1] &quot;AGE&quot; &quot;RECENTMI&quot; &quot;cardioshock&quot; &quot;DIABETES&quot; [5] &quot;hypertension&quot; &quot;BMI&quot; &quot;currsmoker&quot; &quot;msrenaldis&quot; [9] &quot;numdisvessels&quot; &quot;intrapostmi&quot; &quot;dischargestatus&quot; &quot;S_DEATH&quot; [13] &quot;S_TVR&quot; &quot;ID&quot; &quot;DT_INDEX&quot; &quot;DT_DEATH&quot; [17] &quot;DT_TVR&quot; &quot;DT_LFU&quot; &quot;gender&quot; Sometimes variable names have mixed cases, have underscores, or even spaces (especially if reading in data from Excel). The make.names function removes special characters and spaces from variables names. The option allow_ turns underscores to periods. The tolower function changes text so that they are all lowercase. &gt; # Change variable names to all lowercase and change underscores to &#39;.&#39; &gt; names(d1) &lt;- tolower(make.names(names(d1), allow_ = F)) &gt; names(d1) [1] &quot;age&quot; &quot;recentmi&quot; &quot;cardioshock&quot; &quot;diabetes&quot; [5] &quot;hypertension&quot; &quot;bmi&quot; &quot;currsmoker&quot; &quot;msrenaldis&quot; [9] &quot;numdisvessels&quot; &quot;intrapostmi&quot; &quot;dischargestatus&quot; &quot;s.death&quot; [13] &quot;s.tvr&quot; &quot;id&quot; &quot;dt.index&quot; &quot;dt.death&quot; [17] &quot;dt.tvr&quot; &quot;dt.lfu&quot; &quot;gender&quot; &gt; &gt; # quick exploration of data &gt; library(summarytools) Registered S3 method overwritten by &#39;pryr&#39;: method from print.bytes Rcpp Warning in fun(libname, pkgname): couldn&#39;t connect to display &quot;:0&quot; system might not have X11 capabilities; in case of errors when using dfSummary(), set st_options(use.x11 = FALSE) Attaching package: &#39;summarytools&#39; The following object is masked from &#39;package:tibble&#39;: view &gt; dfSummary(d1, graph.col = FALSE) Data Frame Summary d1 Dimensions: 2000 x 19 Duplicates: 0 -------------------------------------------------------------------------------------------------------------------------------- No Variable Label Stats / Values Freqs (% of Valid) Valid Missing ---- ----------------- ------------------------------- ---------------------------- ---------------------- ---------- ---------- 1 age Age, yrs Mean (sd) : 66.6 (12.1) 65 distinct values 2000 0 [numeric] min &lt; med &lt; max: (100%) (0%) 25 &lt; 67 &lt; 98 IQR (CV) : 18 (0.2) 2 recentmi Recent MI Mean (sd) : 2.8 (1.2) 1 : 417 (21.1%) 1972 28 [numeric] min &lt; med &lt; max: 2 : 319 (16.2%) (98.6%) (1.4%) 1 &lt; 3 &lt; 4 3 : 404 (20.5%) IQR (CV) : 2 (0.4) 4 : 832 (42.2%) 3 cardioshock Cardiogenic shock Min : 1 1 : 1920 (96.2%) 1996 4 [numeric] Mean : 1 2 : 76 ( 3.8%) (99.8%) (0.2%) Max : 2 4 diabetes Diabetes mellitus Min : 1 1 : 1408 (71.0%) 1984 16 [numeric] Mean : 1.3 2 : 576 (29.0%) (99.2%) (0.8%) Max : 2 5 hypertension Hypertension Min : 1 1 : 359 (18.6%) 1928 72 [numeric] Mean : 1.8 2 : 1569 (81.4%) (96.4%) (3.6%) Max : 2 6 bmi Body Mass Index (kg/sq.m) Mean (sd) : 30.3 (6.1) 1215 distinct values 1987 13 [numeric] min &lt; med &lt; max: (99.35%) (0.65%) 14.3 &lt; 29.4 &lt; 65.4 IQR (CV) : 7.5 (0.2) 7 currsmoker Current Smoker Min : 1 1 : 1586 (82.1%) 1932 68 [numeric] Mean : 1.2 2 : 346 (17.9%) (96.6%) (3.4%) Max : 2 8 msrenaldis Moderate/Severe renal disease Min : 1 1 : 1889 (95.4%) 1980 20 [numeric] Mean : 1 2 : 91 ( 4.6%) (99%) (1%) Max : 2 9 numdisvessels Number of diseased vessels Mean (sd) : 1.7 (0.9) 0 : 57 ( 2.9%) 1982 18 [numeric] min &lt; med &lt; max: 1 : 898 (45.3%) (99.1%) (0.9%) 0 &lt; 2 &lt; 3 2 : 528 (26.6%) IQR (CV) : 2 (0.5) 3 : 499 (25.2%) 10 intrapostmi MI complication (PTCA Reg) Min : 1 1 : 1925 (96.2%) 2000 0 [numeric] Mean : 1 2 : 75 ( 3.8%) (100%) (0%) Max : 2 11 dischargestatus In-hospital death Min : 1 1 : 1976 (98.8%) 2000 0 [numeric] Mean : 1 2 : 24 ( 1.2%) (100%) (0%) Max : 2 12 s.death Death Status Min : 0 0 : 1392 (69.6%) 2000 0 [numeric] Mean : 0.3 1 : 608 (30.4%) (100%) (0%) Max : 1 13 s.tvr TVR Status Min : 0 0 : 1579 (79.0%) 2000 0 [numeric] Mean : 0.2 1 : 421 (21.1%) (100%) (0%) Max : 1 14 id Sample ID no. Mean (sd) : 1000.5 (577.5) 2000 distinct values 2000 0 [numeric] min &lt; med &lt; max: (100%) (0%) 1 &lt; 1000.5 &lt; 2000 IQR (CV) : 999.5 (0.6) 15 dt.index Baseline date min : 1990-01-02 1689 distinct values 2000 0 [Date] med : 1997-11-06 (100%) (0%) max : 2005-12-28 range : 15y 11m 26d 16 dt.death Death date min : 1990-05-01 588 distinct values 608 1392 [Date] med : 2001-04-22 (30.4%) (69.6%) max : 2014-11-12 range : 24y 6m 11d 17 dt.tvr TVR date min : 1990-02-02 403 distinct values 421 1579 [Date] med : 2001-05-15 (21.05%) (78.95%) max : 2015-09-19 range : 25y 7m 17d 18 dt.lfu LFU date min : 1990-03-31 1767 distinct values 2000 0 [Date] med : 2003-01-12 (100%) (0%) max : 2017-10-10 range : 27y 6m 10d 19 gender Gender 1. Female 588 (29.4%) 2000 0 [character] 2. Male 1412 (70.6%) (100%) (0%) -------------------------------------------------------------------------------------------------------------------------------- There are several variables that are coded as numbers that we want treated as factors with descriptive values (e.g. No/Yes). The code below loops over all of these No/Yes variables and changes the variables to factors. Tip: this code only works if you specify the variables using d1[[i]]. It will not work if you use d1[,i]. &gt; # Change variables with the values 1/2 to formats with the values No/Yes. Note &gt; # the use of d1[[i]] to indicate each variable &gt; ynvars &lt;- c(&quot;cardioshock&quot;, &quot;diabetes&quot;, &quot;hypertension&quot;, &quot;currsmoker&quot;, &quot;msrenaldis&quot;, + &quot;intrapostmi&quot;) &gt; for (i in ynvars) d1[[i]] &lt;- factor(d1[[i]], levels = 1:2, labels = c(&quot;No&quot;, &quot;Yes&quot;)) Now create some other factors. &gt; # Change discharge status variable to Alive/Deceased &gt; d1$dischargestatus &lt;- factor(d1$dischargestatus, levels = 1:2, labels = c(&quot;Alive&quot;, + &quot;Deceased&quot;)) In the code below, the level ‘Never’ was moved to the first position so that it can serve as the reference group in models. In models, R by default uses the first level as the reference. &gt; # Chance order of recentmi levels &gt; d1$recentmi &lt;- factor(d1$recentmi, levels = 4:1, labels = c(&quot;Never&quot;, &quot;&gt;7 days&quot;, &quot;1-7 days&quot;, + &quot;&lt;24 hrs&quot;), ordered = TRUE) This next section of code is a bit tricky, but it demonstrates how to create a mapping between variable labels and variable names, which is useful for tableby and plotting. There are several different functions introduced here including sapply, unlist, and function(x). Step 1 essentially takes a dataframe (which is a special type of list), then it uses the sapply function to look at each element in the list (here, each variable) and extracts the label. Finally it takes the results and changes them to be a vector. Step 5 uses the filter() function which is a part of the dplyr package. It keeps all observations where the labels variable is missing, as determined by is.na(). &gt; # 1. Pull all available labels arsenal has the function labels that extracts all &gt; # labels in the df &gt; d1_labels &lt;- labels(d1) &gt; &gt; # 2. Identify which variables don&#39;t have a label Which variables are missing &gt; names(d1)[names(d1) %nin% names(unlist(d1_labels))] [1] &quot;recentmi&quot; &quot;cardioshock&quot; &quot;diabetes&quot; &quot;hypertension&quot; [5] &quot;currsmoker&quot; &quot;msrenaldis&quot; &quot;intrapostmi&quot; &quot;dischargestatus&quot; &gt; &gt; # 3. Add labels to those variables &gt; d1_labels$cardioshock &lt;- &quot;Cardiogenic shock&quot; &gt; d1_labels$currsmoker &lt;- &quot;Current smoker&quot; &gt; d1_labels$diabetes &lt;- &quot;Diabetes mellitus&quot; &gt; d1_labels$dischargestatus &lt;- &quot;In-hospital death&quot; &gt; d1_labels$hypertension &lt;- &quot;Hypertension&quot; &gt; d1_labels$intrapostmi &lt;- &quot;MI complication&quot; &gt; d1_labels$msrenaldis &lt;- &quot;Moderate/Severe renal disease&quot; &gt; d1_labels$recentmi &lt;- &quot;Recent MI&quot; &gt; &gt; # create a vector of covariates &gt; covar &lt;- c(&quot;age&quot;, &quot;gender&quot;, &quot;recentmi&quot;, &quot;cardioshock&quot;, &quot;diabetes&quot;, &quot;hypertension&quot;, + &quot;bmi&quot;, &quot;currsmoker&quot;, &quot;msrenaldis&quot;, &quot;numdisvessels&quot;, &quot;intrapostmi&quot;) 2.2.2 Investigate missing data From the dfsummary it is apparent that there is some missing data. Before doing any modeling, it would be helpful to better understand the missingness patterns. The apply() function is helpful in that it takes a matrix or dataframe, and does something to each row (MARGIN=1) or column (MARGIN=2). In this case, it uses the function sum() to summarize the number of missings found in the dataframe is.na(d1). &gt; # How many missing values are there for each variable? &gt; tmp &lt;- is.na(d1) &gt; head(tmp) age recentmi cardioshock diabetes hypertension bmi currsmoker [1,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE [2,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE [3,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE [4,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE [5,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE [6,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE msrenaldis numdisvessels intrapostmi dischargestatus s.death s.tvr id [1,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE [2,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE [3,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE [4,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE [5,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE [6,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE dt.index dt.death dt.tvr dt.lfu gender [1,] FALSE TRUE TRUE FALSE FALSE [2,] FALSE TRUE TRUE FALSE FALSE [3,] FALSE TRUE TRUE FALSE FALSE [4,] FALSE TRUE TRUE FALSE FALSE [5,] FALSE TRUE TRUE FALSE FALSE [6,] FALSE TRUE TRUE FALSE FALSE &gt; sum(tmp[, 2]) # look at 1 variable [1] 28 &gt; apply(tmp, MARGIN = 2, FUN = sum) # use apply to examine all variables age recentmi cardioshock diabetes hypertension 0 28 4 16 72 bmi currsmoker msrenaldis numdisvessels intrapostmi 13 68 20 18 0 dischargestatus s.death s.tvr id dt.index 0 0 0 0 0 dt.death dt.tvr dt.lfu gender 1392 1579 0 0 &gt; &gt; # What is the distribution of missing values by subject? &gt; sum(tmp[2, ]) # look at 1 subject [1] 2 &gt; subj.na &lt;- apply(tmp, MARGIN = 1, FUN = sum) # use apply to examine all subjects &gt; table(subj.na) subj.na 0 1 2 3 4 5 99 733 1042 115 7 4 &gt; &gt; # Repeat, but only include covariates &gt; subj.na &lt;- apply(is.na(d1[, covar]), MARGIN = 1, FUN = sum) &gt; table(subj.na) subj.na 0 1 2 3 4 1785 198 13 1 3 There are a number of different packages available to visually explore missing data. The code below illustrates one package called naniar written by Nick Tierney. &gt; library(naniar) &gt; &gt; vis_miss(d1[, covar], cluster = TRUE) # cluster observations by missingness &gt; &gt; gg_miss_var(d1[, covar], show_pct = TRUE) &gt; gg_miss_var(d1[, c(&quot;dischargestatus&quot;, covar)], show_pct = TRUE, facet = dischargestatus) Classification trees using the package rpart can also sometimes be helpful when looking for missingness patterns, especially if you want to understand why a particular variable is missing and whether it is related to any other variable. &gt; library(rpart) &gt; library(rpart.plot) &gt; &gt; # determine what is associated with missing information about hypertension &gt; fit &lt;- rpart(is.na(hypertension) ~ ., data = d1, method = &quot;class&quot;, minsplit = 10) &gt; printcp(fit) Classification tree: rpart(formula = is.na(hypertension) ~ ., data = d1, method = &quot;class&quot;, minsplit = 10) Variables actually used in tree construction: [1] age cardioshock dischargestatus dt.index [5] dt.lfu id recentmi Root node error: 72/2000 = 0.036 n= 2000 CP nsplit rel error xerror xstd 1 0.013889 0 1.00000 1.0000 0.11571 2 0.010417 4 0.93056 1.0694 0.11951 3 0.010000 8 0.88889 1.0694 0.11951 &gt; rpart.plot(fit, type = 2, extra = 101) Running rpart() with the default settings didn’t create any splits because it requires 20 subjects in a node before any splits can be made (minsplit option). Based on the printcp() summary, it appears that 4 splits are necessary to gain much of an improvement in the classification error. The plot suggests that there might be more missingness for those who were alive at discharge and were age 58+. For now, we are going to proceed, recognizing that missingness is an issue. 2.2.3 Kaplan-Meier In order to create a KM curve we need time variables and right now we just have dates. &gt; # First attempt - days from Index Date to LFU Date &gt; d1$tm2death &lt;- d1$dt.lfu - d1$dt.index &gt; summary(d1$tm2death) Length Class Mode 2000 difftime numeric &gt; # This is not so helpful, because subtracting dates creates an object of class &gt; # &#39;difftime&#39; Instead, let&#39;s make a numeric object &gt; d1$tm2death &lt;- as.numeric(d1$dt.lfu - d1$dt.index) &gt; summary(d1$tm2death) Min. 1st Qu. Median Mean 3rd Qu. Max. 1.0 981.2 1862.0 1915.8 2653.2 4598.0 &gt; &gt; # Create a default KM curve &gt; library(survival) &gt; fit &lt;- survfit(Surv(tm2death, s.death) ~ gender, data = d1) &gt; plot(fit, col = 1:2, lty = 1:2, xscale = 365.25, xlab = &quot;Follow-up, years&quot;, ylab = &quot;Probability of Survival&quot;) &gt; legend(&quot;topright&quot;, legend = c(&quot;Female&quot;, &quot;Male&quot;), col = 1:2, lty = 1:2, bty = &quot;n&quot;) &gt; &gt; # If you want the survival estimates at specific time points, use the summary &gt; # function &gt; summary(fit, times = 365.25 * 0:10) Call: survfit(formula = Surv(tm2death, s.death) ~ gender, data = d1) gender=Female time n.risk n.event survival std.err lower 95% CI upper 95% CI 0 588 0 1.000 0.0000 1.000 1.000 365 514 50 0.913 0.0117 0.891 0.937 730 480 20 0.877 0.0137 0.851 0.905 1096 438 22 0.836 0.0157 0.806 0.867 1461 364 26 0.783 0.0178 0.749 0.819 1826 306 31 0.713 0.0202 0.674 0.753 2192 249 23 0.654 0.0220 0.612 0.698 2557 202 13 0.617 0.0230 0.573 0.663 2922 141 10 0.578 0.0246 0.532 0.629 3287 118 7 0.549 0.0257 0.501 0.602 3652 46 4 0.514 0.0299 0.458 0.576 gender=Male time n.risk n.event survival std.err lower 95% CI upper 95% CI 0 1412 0 1.000 0.00000 1.000 1.000 365 1225 111 0.919 0.00735 0.905 0.934 730 1132 52 0.880 0.00886 0.862 0.897 1096 1014 54 0.836 0.01021 0.816 0.856 1461 895 40 0.802 0.01115 0.780 0.824 1826 748 41 0.762 0.01218 0.739 0.786 2192 610 38 0.719 0.01334 0.694 0.746 2557 502 24 0.689 0.01416 0.662 0.717 2922 295 23 0.643 0.01615 0.612 0.675 3287 247 10 0.620 0.01714 0.587 0.654 3652 110 6 0.592 0.01983 0.554 0.632 &gt; &gt; # Fancier plot including table indicating number at risk &gt; library(survminer) Loading required package: ggpubr Loading required package: magrittr Warning: package &#39;magrittr&#39; was built under R version 4.0.2 Attaching package: &#39;magrittr&#39; The following object is masked from &#39;package:purrr&#39;: set_names The following object is masked from &#39;package:tidyr&#39;: extract &gt; &gt; ggsurvplot(fit, risk.table = TRUE, pval = TRUE, censor = FALSE, xscale = 365.25, + break.time.by = 5 * 365.25) Warning: Vectorized input to `element_text()` is not officially supported. Results may be unexpected or may change in future versions of ggplot2. 2.2.4 Cumulative Incidence Now look at the time to TVR where death is treated as a competing risk. &gt; # Create time to TVR (if event) or LFU The pmin function estimates the smallest &gt; # value, by row, not including missings &gt; d1$tm2tvr &lt;- as.numeric(pmin(d1$dt.tvr, d1$dt.lfu, na.rm = T) - d1$dt.index) &gt; &gt; # Create event variable with 3 levels: censor, TVR, death &gt; with(d1, table(death = s.death, tvr = s.tvr)) tvr death 0 1 0 1078 314 1 501 107 &gt; d1$event &lt;- with(d1, ifelse(s.tvr == 0, 2 * s.death, 1)) &gt; table(d1$event) 0 1 2 1078 421 501 &gt; # In order to do competing risks, the status variable must be a factor &gt; d1$event &lt;- factor(d1$event, levels = 0:2, labels = c(&quot;censor&quot;, &quot;tvr&quot;, &quot;death&quot;)) &gt; &gt; # confirm coding makes sense &gt; library(arsenal) &gt; summary(freqlist(table(new_event = d1$event, tvr = d1$s.tvr, death = d1$s.death))) |new_event |tvr |death | Freq| Cumulative Freq| Percent| Cumulative Percent| |:---------|:---|:-----|----:|---------------:|-------:|------------------:| |censor |0 |0 | 1078| 1078| 53.90| 53.90| |tvr |1 |0 | 314| 1392| 15.70| 69.60| | | |1 | 107| 1499| 5.35| 74.95| |death |0 |1 | 501| 2000| 25.05| 100.00| &gt; &gt; # Fit the cumulative incidence curves &gt; fit &lt;- survfit(Surv(tm2tvr, event) ~ gender, data = d1) &gt; fit Call: survfit(formula = Surv(tm2tvr, event) ~ gender, data = d1) n nevent rmean* gender=Female, (s0) 588 0 2658.4914 gender=Male, (s0) 1412 0 2755.6290 gender=Female, tvr 588 102 803.9427 gender=Male, tvr 1412 319 945.0840 gender=Female, death 588 177 1135.5658 gender=Male, death 1412 324 897.2870 *mean time in state, restricted (max time = 4598 ) &gt; plot(fit, col = c(1, 1, 2, 2), lty = c(2, 1, 2, 1), xscale = 365.25, xlab = &quot;Follow-up, years&quot;, + ylab = &quot;Probability&quot;) &gt; legend(&quot;topleft&quot;, c(&quot;female: tvr&quot;, &quot;male: tvr&quot;, &quot;female: death&quot;, &quot;male: death&quot;), + lty = c(2, 1, 2, 1), col = c(1, 1, 2, 2), bty = &quot;n&quot;) &gt; &gt; ## look at only certain portions of the survfit object rows=strata, columns=states &gt; dim(fit) strata states 2 3 &gt; fit$strata gender=Female gender=Male 499 1020 &gt; fit$states [1] &quot;(s0)&quot; &quot;tvr&quot; &quot;death&quot; &gt; &gt; # re-plot, just including tvr &gt; fit2 &lt;- fit[, 2] &gt; fit2 # confirm that this just picks up the tvr events Call: survfit(formula = Surv(tm2tvr, event) ~ gender, data = d1) n nevent rmean* gender=Female, tvr 588 102 803.9427 gender=Male, tvr 1412 319 945.0840 *mean time in state, restricted (max time = 4598 ) &gt; &gt; plot(fit2, col = 1:2, lty = 1:2, xscale = 365.25, xlab = &quot;Follow-up, years&quot;, ylab = &quot;Cumulative Incidence of TVR&quot;, + xmax = 11 * 365.25) &gt; legend(&quot;topleft&quot;, legend = c(&quot;Female&quot;, &quot;Male&quot;), col = 1:2, lty = 1:2, bty = &quot;n&quot;) &gt; &gt; ## Fit model &gt; cfit &lt;- coxph(Surv(tm2tvr, event) ~ gender, data = d1, id = id) &gt; &gt; ## If you are just interested in tvr, then you get the same results using &gt; cfit2 &lt;- coxph(Surv(tm2tvr, event == &quot;tvr&quot;) ~ gender, data = d1, id = id) 2.2.5 Linear regression model Assess how BMI differs by age and gender, then check the model assumptions. Don’t assume that the functional form for age is linear. The splines package includes the natural splines function ns. &gt; library(splines) # needed to load the ns() function &gt; fit &lt;- lm(bmi ~ ns(age, df = 3) + gender, data = d1) &gt; summary(fit) Call: lm(formula = bmi ~ ns(age, df = 3) + gender, data = d1) Residuals: Min 1Q Median 3Q Max -17.284 -4.034 -0.870 3.178 33.668 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 30.7571 1.5463 19.891 &lt; 2e-16 *** ns(age, df = 3)1 -1.3705 0.8080 -1.696 0.0900 . ns(age, df = 3)2 -1.9786 3.4576 -0.572 0.5672 ns(age, df = 3)3 -7.3226 1.2885 -5.683 1.52e-08 *** genderMale -0.6195 0.2977 -2.081 0.0376 * --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 5.945 on 1982 degrees of freedom (13 observations deleted due to missingness) Multiple R-squared: 0.05133, Adjusted R-squared: 0.04942 F-statistic: 26.81 on 4 and 1982 DF, p-value: &lt; 2.2e-16 &gt; &gt; # plot the curvature &gt; termplot(fit, term = 1, se = T, rug = T) &gt; &gt; # visually check model assumptions &gt; plot(fit) &gt; &gt; # summarize residuals &gt; summary(resid(fit)) Min. 1st Qu. Median Mean 3rd Qu. Max. -17.2845 -4.0336 -0.8697 0.0000 3.1778 33.6684 The following code plots the relationship between age and BMI separately for males and females with a smoother through the points, providing further insight into the data. &gt; ggplot(d1, aes(x = age, y = bmi)) + geom_point(alpha = 0.1) + geom_smooth(span = 1) + + facet_wrap(~gender) `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; Warning: Removed 13 rows containing non-finite values (stat_smooth). Warning: Removed 13 rows containing missing values (geom_point). 2.2.6 Logistic regression models Assess which risk factors predict the discharge status: dischargestatus. &gt; d1$dischargestatus01 &lt;- as.numeric(d1$dischargestatus) - 1 &gt; with(d1, table(dischargestatus01, dischargestatus)) dischargestatus dischargestatus01 Alive Deceased 0 1976 0 1 0 24 &gt; &gt; # Look at a simple model: the association between gender and in-hospital death &gt; fit3 &lt;- glm(dischargestatus01 ~ gender, data = d1, family = &quot;binomial&quot;) &gt; summary(fit3) Call: glm(formula = dischargestatus01 ~ gender, family = &quot;binomial&quot;, data = d1) Deviance Residuals: Min 1Q Median 3Q Max -0.1689 -0.1689 -0.1689 -0.1168 3.1593 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -4.9836 0.5016 -9.935 &lt;2e-16 *** genderMale 0.7408 0.5499 1.347 0.178 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 260.01 on 1999 degrees of freedom Residual deviance: 257.89 on 1998 degrees of freedom AIC: 261.89 Number of Fisher Scoring iterations: 7 The broom package allows users to extract information from a model and save it as a data.frame. The two main functions in broom are tidy(), which returns a tidy version of the model coefficients, and glance() which returns a one-row glance at the model’s statistics. There is also the function augment() which augments the original data with information such as the fitted values and residuals. &gt; # Look at a tidy model summary (data frame) &gt; library(broom) &gt; # &#39;exponentiate=TRUE&#39; exponentiates the estimates, including the intercept &gt; tmp &lt;- tidy(fit3, exponentiate = TRUE, conf.int = TRUE) &gt; print(tmp, digits = 3) # A tibble: 2 x 7 term estimate std.error statistic p.value conf.low conf.high &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 (Intercept) 0.00685 0.502 -9.93 2.94e-23 0.00212 0.0160 2 genderMale 2.10 0.550 1.35 1.78e- 1 0.790 7.24 &gt; # Remove the intercept line &gt; print(tmp[-1, ], digits = 3) # A tibble: 1 x 7 term estimate std.error statistic p.value conf.low conf.high &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 genderMale 2.10 0.550 1.35 0.178 0.790 7.24 &gt; glance(fit3) # A tibble: 1 x 7 null.deviance df.null logLik AIC BIC deviance df.residual &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; 1 260. 1999 -129. 262. 273. 258. 1998 This is fine for a small number of models, but if you want to summarize results for multiple models, perhaps adjusting for a certain set of covariates, then it is time to use a different tool. The modelsum() in arsenal creates such summaries. For logistic regression models (family='binomial'), the results are automatically shown with odd’s ratios and confidence intervals, plus the concordance (AUC) value and the number of missing values for that variable. &gt; # Use formulize in arsenal to create a formula to pass to modelsum &gt; myform &lt;- formulize(y = &quot;dischargestatus01&quot;, x = covar) &gt; tmp &lt;- modelsum(myform, family = &quot;binomial&quot;, data = d1) &gt; summary(tmp, show.intercept = F, title = &quot;Hospital Discharge: Univariate analysis&quot;) Hospital Discharge: Univariate analysis OR CI.lower.OR CI.upper.OR p.value concordance Nmiss Age, yrs 1.020 0.986 1.057 0.259 0.555 0 Gender Male 2.098 0.790 7.236 0.178 0.564 0 recentmi .L 5.914 2.554 16.883 &lt; 0.001 0.742 28 recentmi .Q 1.260 0.452 3.903 0.662 recentmi .C 0.760 0.201 2.227 0.637 cardioshock Yes 91.915 36.761 262.524 &lt; 0.001 0.855 4 diabetes Yes 0.978 0.347 2.418 0.963 0.502 16 hypertension Yes 0.415 0.157 1.213 0.086 0.584 72 Body Mass Index (kg/sq.m) 0.934 0.860 1.007 0.094 0.588 13 currsmoker Yes 1.982 0.697 4.978 0.164 0.561 68 msrenaldis Yes 1.038 0.058 5.067 0.971 0.501 20 Number of diseased vessels 1.407 0.880 2.270 0.154 0.577 18 intrapostmi Yes 2.370 0.375 8.251 0.249 0.523 0 &gt; &gt; # Note - because recentmi is an ordered factor, R tries to model it with &gt; # Linear/Quadradic/Cubic. Try creating covar2 - see the difference &gt; covar2 &lt;- c(&quot;age&quot;, &quot;gender&quot;, &quot;as.numeric(recentmi)&quot;, &quot;cardioshock&quot;, &quot;diabetes&quot;, &quot;hypertension&quot;, + &quot;bmi&quot;, &quot;currsmoker&quot;, &quot;msrenaldis&quot;, &quot;numdisvessels&quot;, &quot;intrapostmi&quot;) &gt; myform2 &lt;- formulize(y = &quot;dischargestatus01&quot;, x = covar2) &gt; tmp2 &lt;- modelsum(myform2, family = &quot;binomial&quot;, data = d1) &gt; summary(tmp2, show.intercept = F, title = &quot;Hospital Discharge: Univariate analysis&quot;) Hospital Discharge: Univariate analysis OR CI.lower.OR CI.upper.OR p.value concordance Nmiss Age, yrs 1.020 0.986 1.057 0.259 0.555 0 Gender Male 2.098 0.790 7.236 0.178 0.564 0 as.numeric(recentmi) 2.236 1.547 3.426 &lt; 0.001 0.742 28 cardioshock Yes 91.915 36.761 262.524 &lt; 0.001 0.855 4 diabetes Yes 0.978 0.347 2.418 0.963 0.502 16 hypertension Yes 0.415 0.157 1.213 0.086 0.584 72 Body Mass Index (kg/sq.m) 0.934 0.860 1.007 0.094 0.588 13 currsmoker Yes 1.982 0.697 4.978 0.164 0.561 68 msrenaldis Yes 1.038 0.058 5.067 0.971 0.501 20 Number of diseased vessels 1.407 0.880 2.270 0.154 0.577 18 intrapostmi Yes 2.370 0.375 8.251 0.249 0.523 0 &gt; # save results as a data frame and output results to a csv file &gt; foroutput &lt;- as.data.frame(tmp) &gt; head(foroutput) y.term y.label strata.term adjustment model term 1 dischargestatus01 dischargestatus01 unadjusted 1 (Intercept) 2 dischargestatus01 dischargestatus01 unadjusted 1 age 3 dischargestatus01 dischargestatus01 unadjusted 2 (Intercept) 4 dischargestatus01 dischargestatus01 unadjusted 2 genderMale 5 dischargestatus01 dischargestatus01 unadjusted 3 (Intercept) 6 dischargestatus01 dischargestatus01 unadjusted 3 recentmi.L label term.type OR CI.lower.OR CI.upper.OR p.value 1 (Intercept) Intercept 0.003153183 0.0002420665 0.03147134 3.184984e-06 2 Age, yrs Term 1.020021318 0.9861477653 1.05679269 2.592280e-01 3 (Intercept) Intercept 0.006849315 0.0021209595 0.01598169 2.943694e-23 4 Gender Male Term 2.097701072 0.7897245602 7.23552308 1.778864e-01 5 (Intercept) Intercept 0.009989839 0.0055506795 0.01593187 3.116393e-68 6 recentmi .L Term 5.914143128 2.5537218993 16.88340502 1.463148e-04 concordance Nmiss 1 0.5550038 0 2 0.5550038 0 3 0.5644399 0 4 0.5644399 0 5 0.7420966 28 6 0.7420966 28 &gt; write.csv(foroutput, file = &quot;~/ibm/testoutput.csv&quot;) You can also use modelsum to look at results after adjusting for variables such as age and gender. &gt; tmp2 &lt;- modelsum(dischargestatus01 ~ as.numeric(recentmi) + cardioshock, adjust = ~age + + gender, data = d1, family = &quot;binomial&quot;) &gt; summary(tmp2, show.intercept = F, show.adjust = F, title = &quot;Hospital Discharge: Results of key variables after adjusting for age and gender&quot;) Hospital Discharge: Results of key variables after adjusting for age and gender OR CI.lower.OR CI.upper.OR p.value concordance Nmiss as.numeric(recentmi) 2.333 1.600 3.609 &lt; 0.001 0.784 28 cardioshock Yes 103.312 40.588 300.457 &lt; 0.001 0.863 4 Alternative code for looping through variables is shown at the end of this document. You might also want to look at the functional form of age as it relates to the endpoint. The termplot() function is a quick way to see if there are indications that the relationship may be non-linear. Here we used the spline function ns() with 3 degrees of freedom to look for non-linearity. &gt; fit4 &lt;- glm(dischargestatus01 ~ ns(age, df = 3), data = d1, family = &quot;binomial&quot;) &gt; termplot(fit4, se = TRUE, rug = TRUE) &gt; summary(fit4) Call: glm(formula = dischargestatus01 ~ ns(age, df = 3), family = &quot;binomial&quot;, data = d1) Deviance Residuals: Min 1Q Median 3Q Max -0.4171 -0.1704 -0.1521 -0.1415 3.2127 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -10.895 4.758 -2.290 0.0220 * ns(age, df = 3)1 2.789 2.489 1.120 0.2626 ns(age, df = 3)2 14.263 9.827 1.451 0.1467 ns(age, df = 3)3 4.356 2.441 1.784 0.0744 . --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 260.01 on 1999 degrees of freedom Residual deviance: 256.00 on 1996 degrees of freedom AIC: 264 Number of Fisher Scoring iterations: 8 &gt; anova(fit4, test = &quot;Chi&quot;) Analysis of Deviance Table Model: binomial, link: logit Response: dischargestatus01 Terms added sequentially (first to last) Df Deviance Resid. Df Resid. Dev Pr(&gt;Chi) NULL 1999 260.01 ns(age, df = 3) 3 4.0076 1996 256.00 0.2606 &gt; &gt; # Test whether non-linearity is significant by comparing to linear model &gt; fit5 &lt;- glm(dischargestatus01 ~ age, data = d1, family = &quot;binomial&quot;) &gt; anova(fit5, fit4, test = &quot;Chi&quot;) Analysis of Deviance Table Model 1: dischargestatus01 ~ age Model 2: dischargestatus01 ~ ns(age, df = 3) Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi) 1 1998 258.7 2 1996 256.0 2 2.7026 0.2589 2.2.7 Cox regression models Assess which risk factors predict the endpoint tm2death. &gt; # First, a simple model for gender only &gt; fit6 &lt;- coxph(Surv(tm2death, s.death) ~ gender, data = d1) &gt; summary(fit6) Call: coxph(formula = Surv(tm2death, s.death) ~ gender, data = d1) n= 2000, number of events= 608 coef exp(coef) se(coef) z Pr(&gt;|z|) genderMale -0.2029 0.8163 0.0856 -2.371 0.0177 * --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 exp(coef) exp(-coef) lower .95 upper .95 genderMale 0.8163 1.225 0.6902 0.9654 Concordance= 0.517 (se = 0.01 ) Likelihood ratio test= 5.49 on 1 df, p=0.02 Wald test = 5.62 on 1 df, p=0.02 Score (logrank) test = 5.64 on 1 df, p=0.02 The broom package can be used with survival objects as well. &gt; # Look at a tidy model summary (data frame) &gt; tmp &lt;- tidy(fit6, exponentiate = TRUE, conf.int = TRUE) &gt; print(tmp, digits = 3) # A tibble: 1 x 7 term estimate std.error statistic p.value conf.low conf.high &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 genderMale 0.816 0.0856 -2.37 0.0177 0.690 0.965 &gt; glance(fit6) # A tibble: 1 x 15 n nevent statistic.log p.value.log statistic.sc p.value.sc statistic.wald &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 2000 608 5.49 0.0191 5.64 0.0176 5.62 # … with 8 more variables: p.value.wald &lt;dbl&gt;, r.squared &lt;dbl&gt;, # r.squared.max &lt;dbl&gt;, concordance &lt;dbl&gt;, std.error.concordance &lt;dbl&gt;, # logLik &lt;dbl&gt;, AIC &lt;dbl&gt;, BIC &lt;dbl&gt; Here is how you would use modelsum() for Cox models. &gt; myform &lt;- formulize(y = &quot;Surv(tm2death, s.death)&quot;, x = covar2) &gt; tmp &lt;- modelsum(myform, family = &quot;survival&quot;, data = d1) &gt; summary(tmp, show.intercept = F, title = &quot;Overall survival: Univariate analysis&quot;) Overall survival: Univariate analysis HR CI.lower.HR CI.upper.HR p.value concordance Nmiss Age, yrs 1.062 1.054 1.070 &lt; 0.001 0.663 0 Gender Male 0.816 0.690 0.965 0.018 0.517 0 as.numeric(recentmi) 1.093 1.024 1.167 0.008 0.550 28 cardioshock Yes 2.290 1.649 3.181 &lt; 0.001 0.526 4 diabetes Yes 2.207 1.876 2.597 &lt; 0.001 0.586 16 hypertension Yes 2.140 1.653 2.770 &lt; 0.001 0.546 72 Body Mass Index (kg/sq.m) 0.984 0.970 0.998 0.022 0.535 13 currsmoker Yes 0.659 0.514 0.845 0.001 0.525 68 msrenaldis Yes 4.026 3.116 5.202 &lt; 0.001 0.543 20 Number of diseased vessels 1.572 1.434 1.724 &lt; 0.001 0.607 18 intrapostmi Yes 1.028 0.672 1.573 0.899 0.503 0 You might also want to look at the functional form of age as it relates to the endpoint. The termplot() function is a quick way to see if there are indications that the relationship may be non-linear. Here we used the penalized spline pspline() with 4 degrees of freedom to look for non-linearity. &gt; fit7 &lt;- coxph(Surv(tm2death, s.death) ~ pspline(age, df = 4), data = d1) &gt; termplot(fit7, se = TRUE, rug = TRUE) &gt; fit7 # test linear and nonlinear portions of the fit for significance Call: coxph(formula = Surv(tm2death, s.death) ~ pspline(age, df = 4), data = d1) coef se(coef) se2 Chisq DF p pspline(age, df = 4), lin 5.93e-02 3.69e-03 3.69e-03 2.58e+02 1.00 &lt;2e-16 pspline(age, df = 4), non 9.61e+00 3.07 0.024 Iterations: 5 outer, 15 Newton-Raphson Theta= 0.88 Degrees of freedom for terms= 4.1 Likelihood ratio test=269 on 4.07 df, p=&lt;2e-16 n= 2000, number of events= 608 &gt; anova(fit7) # overall test Analysis of Deviance Table Cox model: response is Surv(tm2death, s.death) Terms added sequentially (first to last) loglik Chisq Df Pr(&gt;|Chi|) NULL -4324.7 pspline(age, df = 4) -4190.1 269.33 4.0686 &lt; 2.2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Finally, it is good to do some basic model checks on your results. The coefficient in a Cox model is an average of the estimated beta over all the event times. The proportional hazards model assumes that this coefficient is constant over time, however that is not always true. The cox.zph function creates time-dependent coefficients for more detailed examination. The printout of cox.zph summarizes the correlation of Beta(time) vs time for each variable. The plot of cox.zph visualizes the relationship. It is important to look at the plot to understand the summary. In the coxph function, as with some (but not all) of the other model functions in R, there are several options for handling missing values. The default na.omit option and the na.exclude option both remove any missing values from the fit. They differ in that the former returns residuals only for the non-missing values and the latter returns residuals with the same number of rows as the input data. If you want to compare residuals to the original data then it is more convenient to use na.exclude (not the default); if you are going to calculate summaries such as quantiles then the former is more convenient because missing values will have been removed. &gt; # Change option because we will want to look at residuals later on &gt; options(na.action = na.exclude) &gt; fit8 &lt;- coxph(Surv(tm2death, s.death) ~ age + gender + cardioshock, data = d1) &gt; zfit8 &lt;- cox.zph(fit8) &gt; &gt; zfit8 chisq df p age 40.0 1 2.5e-10 gender 1.5 1 0.22 cardioshock 27.6 1 1.5e-07 GLOBAL 65.3 3 4.3e-14 &gt; plot(zfit8[3]) # look at 3rd variable, hard to view &gt; plot(zfit8[3], resid = FALSE) # plot without residuals &gt; abline(h = coef(fit8)[3], col = 2) # coef estimate &gt; abline(h = 0, col = 3) Based on this, it appears that we might need to treat early deaths (likely those in the hospital) different from those that appear after discharge. Perhaps we might want to start follow-up after discharge if that information is available. Leverage points are also sometimes an issue. Dfbeta residuals offer one way to check for influential points. It allows you to see how much the estimate of Beta would change if one point was deleted. &gt; rr &lt;- resid(fit8, type = &quot;dfbeta&quot;) &gt; dim(rr) [1] 2000 3 &gt; &gt; # color by status - residuals are all in the 4th decimal so nothing too large &gt; plot(d1$age, rr[, 1], col = d1$s.death + 1) 2.2.8 Missingness revisited: Imputation There are multiple packages that do multiple imputation in R (see article for review). In the code below we’ve chosen to use the mice package (Multivariate Imputation via Chained Equations). Recommendations: * need to include the endpoint in the imputation * if using multiple models/endpoints, just impute everything once including all the variables * imputing continuous variables is much easier than categorical - The default “mice” method is predictive mean matching (pmm) for numeric variables, logistic regression (logreg) for two level factors, polytomous regression (polyreg) for unordered categorical variables, and proportional odds regression (polyr) for ordered factors. You can also specify different methods for different variables within the same call. - The mice package does not like dates - Other methods for imputation are also available besides these defaults &gt; library(mice) Attaching package: &#39;mice&#39; The following objects are masked from &#39;package:base&#39;: cbind, rbind &gt; library(dplyr) &gt; &gt; # Create data frame &#39;sub&#39; which excludes date variables, status variables and id &gt; sub &lt;- d1 %&gt;% select(-starts_with(&quot;dt&quot;), -starts_with(&quot;s.&quot;), -id) &gt; # Create 5 imputed datasets &gt; imputed_d1 &lt;- mice(sub, m = 5, printFlag = FALSE, set.seed = 123) # create 5 datasets, don&#39;t print log Warning: Number of logged events: 3 &gt; &gt; # fit multiple models with imputed data, then combine the results &gt; fits &lt;- with(imputed_d1, glm(dischargestatus01 ~ diabetes, family = &quot;binomial&quot;)) &gt; &gt; # Pool function combines the results of the 5 imputed datasets &gt; pool.fits &lt;- pool(fits) &gt; summary(pool.fits) term estimate std.error statistic df p.value 1 (Intercept) -4.3768615 0.2422715 -18.0659339 1662.3695 0.0000000 2 diabetesYes -0.1254765 0.4814559 -0.2606188 612.7132 0.7944741 &gt; # fmi = fraction of information about the coefficients missing due to nonresponse &gt; &gt; # original value &gt; tidy(glm(dischargestatus01 ~ diabetes, data = d1, family = &quot;binomial&quot;)) # A tibble: 2 x 5 term estimate std.error statistic p.value &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 (Intercept) -4.53 0.260 -17.5 3.13e-68 2 diabetesYes -0.0227 0.486 -0.0468 9.63e- 1 This is fine for 1 variable, but what if you want to look at multiple models using the imputed data? &gt; # create a list with 5 elements, each housing one of the new datasets &gt; imp.list &lt;- list() &gt; for (i in 1:5) { + tmp &lt;- complete(imputed_d1, action = i) + imp.list[[i]] &lt;- tmp + } &gt; &gt; # run modelsum on each element of the list, store as a dataframe (again an &gt; # element of a list) &gt; myform &lt;- formulize(y = &quot;dischargestatus01&quot;, x = covar) &gt; &gt; # Write function to return modelsum results as a data frame &gt; myfun &lt;- function(x) { + fit &lt;- modelsum(myform, family = &quot;binomial&quot;, data = x, show.intercept = FALSE, + binomial.stats = c(&quot;estimate&quot;, &quot;std.error&quot;, &quot;p.value&quot;, &quot;concordance&quot;, &quot;Nmiss&quot;)) + return(as.data.frame(fit)) + } &gt; &gt; # For each element in the list (each imputed dataset), run myfun() &gt; tmp &lt;- lapply(imp.list, myfun) &gt; head(tmp[[1]]) y.term y.label strata.term adjustment model 1 dischargestatus01 dischargestatus01 unadjusted 1 2 dischargestatus01 dischargestatus01 unadjusted 2 3 dischargestatus01 dischargestatus01 unadjusted 3 4 dischargestatus01 dischargestatus01 unadjusted 3 5 dischargestatus01 dischargestatus01 unadjusted 3 6 dischargestatus01 dischargestatus01 unadjusted 4 term label term.type estimate std.error p.value 1 age Age, yrs Term 0.01982353 0.01757066 2.592280e-01 2 genderMale Gender Male Term 0.74084202 0.54987517 1.778864e-01 3 recentmi.L recentmi .L Term 1.77999512 0.46803433 1.428797e-04 4 recentmi.Q recentmi .Q Term 0.23067795 0.52772788 6.620277e-01 5 recentmi.C recentmi .C Term -0.27538557 0.58132374 6.356985e-01 6 cardioshockYes cardioshock Yes Term 4.57959159 0.48957295 8.418875e-21 concordance 1 0.5550038 2 0.5644399 3 0.7424089 4 0.7424089 5 0.7424089 6 0.8600709 &gt; &gt; # look at coefficients from all the datasets &gt; &gt; # Create a list with the estimates from each model &gt; model.coef &lt;- lapply(tmp, function(x) x$estimate) &gt; &gt; # use the cbind() function to bind the results together &gt; model.coef2 &lt;- do.call(cbind, model.coef) &gt; &gt; # make this a dataframe &gt; model.coef3 &lt;- data.frame(matrix(model.coef2, nrow = nrow(model.coef2), ncol = ncol(model.coef2))) &gt; &gt; # add in rownames for the variables &gt; rownames(model.coef3) &lt;- tmp[[1]]$term &gt; &gt; # label each column as imp1--imp5 &gt; colnames(model.coef3) &lt;- paste0(&quot;imp&quot;, 1:5) &gt; &gt; # add in the mean of the 5 columns &gt; model.coef3$mean.est &lt;- rowMeans(model.coef3) &gt; &gt; knitr::kable(model.coef3, digits = 3) imp1 imp2 imp3 imp4 imp5 mean.est age 0.020 0.020 0.020 0.020 0.020 0.020 genderMale 0.741 0.741 0.741 0.741 0.741 0.741 recentmi.L 1.780 1.779 1.774 1.773 1.771 1.776 recentmi.Q 0.231 0.227 0.231 0.225 0.229 0.229 recentmi.C -0.275 -0.286 -0.265 -0.274 -0.274 -0.275 cardioshockYes 4.580 4.368 4.580 4.368 4.580 4.495 diabetesYes -0.210 0.001 -0.004 -0.206 -0.208 -0.125 hypertensionYes -1.118 -1.122 -1.298 -1.301 -1.609 -1.289 bmi -0.070 -0.067 -0.065 -0.071 -0.074 -0.070 currsmokerYes 0.448 0.645 0.645 0.649 0.642 0.606 msrenaldisYes -0.127 -0.127 -0.116 -0.127 -0.116 -0.123 numdisvessels 0.343 0.396 0.344 0.233 0.397 0.343 intrapostmiYes 0.863 0.863 0.863 0.863 0.863 0.863 2.3 Resources 2.3.1 Technical details Report created: September 22 2020 &gt; # Grab session info &gt; sessionInfo() R version 3.6.2 (2019-12-12) Platform: x86_64-pc-linux-gnu (64-bit) Running under: CentOS Linux 7 (Core) Matrix products: default BLAS: /usr/lib64/libblas.so.3.4.2 LAPACK: /usr/lib64/liblapack.so.3.4.2 locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=C [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C attached base packages: [1] splines stats graphics grDevices utils datasets methods [8] base other attached packages: [1] mice_3.10.0 broom_0.5.6 survminer_0.4.6 ggpubr_0.2.5 [5] magrittr_1.5 survival_3.2-5 rpart.plot_3.0.8 rpart_4.1-15 [9] naniar_0.5.0 summarytools_0.9.6 arsenal_3.4.0.9000 haven_2.2.0 [13] forcats_0.5.0 stringr_1.4.0 dplyr_1.0.0 purrr_0.3.4 [17] readr_1.3.1 tidyr_1.1.0 tibble_3.0.1 ggplot2_3.3.2 [21] tidyverse_1.3.0 loaded via a namespace (and not attached): [1] nlme_3.1-145 matrixStats_0.56.0 fs_1.3.2 lubridate_1.7.4 [5] httr_1.4.1 tools_3.6.2 backports_1.1.6 utf8_1.1.4 [9] R6_2.4.1 mgcv_1.8-31 DBI_1.1.0 colorspace_1.4-1 [13] nnet_7.3-13 withr_2.1.2 tidyselect_1.1.0 gridExtra_2.3 [17] compiler_3.6.2 cli_2.0.2 rvest_0.3.5 formatR_1.7 [21] xml2_1.3.2 labeling_0.3 bookdown_0.18 scales_1.1.0 [25] checkmate_2.0.0 survMisc_0.5.5 digest_0.6.25 rmarkdown_2.1 [29] base64enc_0.1-3 pkgconfig_2.0.3 htmltools_0.5.0 highr_0.8 [33] dbplyr_1.4.2 rlang_0.4.7 readxl_1.3.1 rstudioapi_0.11 [37] pryr_0.1.4 farver_2.0.3 generics_0.0.2 zoo_1.8-7 [41] jsonlite_1.7.0 rapportools_1.0 Matrix_1.2-18 Rcpp_1.0.4 [45] munsell_0.5.0 fansi_0.4.1 lifecycle_0.2.0 visdat_0.5.3 [49] pROC_1.16.1 stringi_1.4.6 yaml_2.2.1 MASS_7.3-51.5 [53] plyr_1.8.6 grid_3.6.2 crayon_1.3.4 lattice_0.20-40 [57] pander_0.6.4 hms_0.5.3 magick_2.4.0 knitr_1.29 [61] pillar_1.4.4 tcltk_3.6.2 ggsignif_0.6.0 codetools_0.2-16 [65] reprex_0.3.0 glue_1.4.1 evaluate_0.14 data.table_1.12.8 [69] modelr_0.1.6 vctrs_0.3.2 cellranger_1.1.0 gtable_0.3.0 [73] km.ci_0.5-2 assertthat_0.2.1 xfun_0.15 xtable_1.8-4 [77] KMsurv_0.1-5 ellipsis_0.3.1 2.3.2 Packages used haven tidyverse summarytools summarytools with rmarkdown arsenal broom survival naniar mice 2.4 Optional ways to code 2.4.1 Fit multiple models and store results Sometimes the model you are fitting can’t be handled by modelsum. Here is some alternative code for looping through a set of variables and storing the results. &gt; ## how many are there? &gt; nvar &lt;- length(covar) &gt; &gt; ## create matrix for storing results, label rows and columns &gt; fit.results &lt;- matrix(NA, nrow = nvar, ncol = 4, dimnames = list(covar, c(&quot;N&quot;, &quot;coef&quot;, + &quot;std&quot;, &quot;p.value&quot;))) &gt; &gt; ## loop through the variables &gt; for (i in 1:nvar) { + + ## if the variable is in my dataset, proceed + if (!is.na(match(covar[i], names(d1)))) { + + ## paste together the formula that I want to use + text &lt;- paste(&quot;coxph(Surv(tm2death,s.death) ~ &quot;, covar[i], &quot; , data=d1)&quot;, + sep = &quot;&quot;) + fit &lt;- eval(parse(text = text)) + + ## pull off the summary, print + prob &lt;- summary(fit) + + ## pull off the coefficient and std.error (last row of fit) + fit.results[i, 2:4] &lt;- prob$coef[nrow(prob$coef), c(1, 3, 5)] + fit.results[i, 1] &lt;- prob$n + } + } 2.4.2 Fit models “by” some variable In SAS you can run a model “by” some variable, such as gender. In R you can do the same thing using the following code. The group_by() function tells R to run the analysis by that variable (or variables) and the do() function tells R what to do. &gt; ans &lt;- d1 %&gt;% group_by(gender) %&gt;% do(tidy(coxph(Surv(tm2death, s.death) ~ age + + cardioshock, data = .data), exponentiate = T, confint = T)) &gt; ans # A tibble: 4 x 8 # Groups: gender [2] gender term estimate std.error statistic p.value conf.low conf.high &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 Female age 1.03 0.00636 5.41 6.27e- 8 1.02 1.05 2 Female cardioshockYes 1.73 0.298 1.83 6.65e- 2 0.963 3.10 3 Male age 1.08 0.00503 15.1 1.15e-51 1.07 1.09 4 Male cardioshockYes 3.26 0.203 5.83 5.65e- 9 2.19 4.86 "],
["appendix.html", "3 Appendix 3.1 Appendix 1: tidyverse package overviews 3.2 Appendix 2: R for SAS programmers", " 3 Appendix 3.1 Appendix 1: tidyverse package overviews 3.1.1 dplyr The package dplyr focuses on transforming and summarizing tabular data with rows and columns. The package contains a set of functions (or “verbs”) that perform common data manipulation operations such as filtering for rows, selecting specific columns, re-ordering rows, adding new columns and summarizing data. In addition, dplyr contains a useful function to perform another common task which is the “split-apply-combine” concept. Important dplyr verbs to remember: select(): select certain columns (fields/variables) of your dataset filter(): select specific rows (observations) of your dataset arrange(): sort specified columns in ascending (default) or descending order mutate(): add new columns or change existing ones summarise(): summarise values group_by(): allows for group operations in the “split-apply-combine” concept rename(): change column names for variables distinct(): get unique values of specified variable set Pipe operator: %&gt;% dplyr imports this operator from another package (magrittr). This operator allows you to pipe the output from one function to the input of another function. Instead of nesting functions (reading from the inside to the outside), the idea of of piping is to read the functions from left to right. Further examples are found at this dplyr tutorial. 3.1.2 tidyr The package tidyr focuses on transposing data, changing from a “wide” format to a “long” format. Important tidyr verbs to remember: pivot_longer() takes multiple columns, and gathers them into key-value pairs: it makes “wide” data longer (function used to be called gather) pivot_wider() takes two columns (key &amp; value) and spreads in to multiple columns, it makes “long” data wider (function used to be called spread) separate() splits a single column into multiple columns unite() combines multiple columns into a single column Further examples are found at this data wrangling site. 3.1.3 lubridate Historically dates have been challenging in R. The package lubridate helps with this and includes some basic date manipulation functions. year(), month(), day(): extract year, month, day hour(), minute(), second(): extract hour, minute, second from a datetime variable date(): extract date from datetime variable mdy(): create date from text string &gt; library(lubridate) &gt; mdy(&quot;July 4th, 2000&quot;) [1] &quot;2000-07-04&quot; &gt; mdy(&quot;7/4/2000&quot;) [1] &quot;2000-07-04&quot; 3.1.4 ggplot2 The package ggplot focuses on displaying data graphically. It is based on the grammer of graphics (Wilkinson, 2005) What Is The Grammar Of Graphics? The basic idea: independently specify plot building blocks and combine them to create just about any kind of graphical display you want. Building blocks of a graph include: data - where is the data located aesthetic mapping - what are your x, y, and grouping variables? geometric object - what type of plot do you want to create statistical transformations - log transform (or others)? scales coordinate system position adjustments faceting - creating separate figures “by” some value, but using the same scale, variables, labels, etc. themes - color schemes used for plots, such as background color, axis defaults theme_gray() (default) theme_bw() theme_classc() Geometic Objects Geometric objects are the actual marks we put on a plot. Examples include: points (geom_point, for scatter plots, dot plots, etc) lines (geom_line, for time series, trend lines, etc) boxplot (geom_boxplot, for boxplots) A plot must have at least one geom; there is no upper limit. You can add a geom to a plot using the + operator You can get a list of available geometric objects using the code below. There are also lots of examples of different types of plots available on the web (just include ggplot in your search). help.search(&quot;geom_&quot;, package = &quot;ggplot2&quot;) Try working through this R graphics tutorial to learn more. 3.2 Appendix 2: R for SAS programmers If you tend to “think SAS”, then making the switch to R can be challenging. A couple book that might help include: SAS and R: Data Management, Statistical Analysis, and Graphics by Kleinman and Horton R for SAS and SPSS Users by Robert Muenchen Below are a few select tasks and the packages/functions that handle those tasks. Table 3.1: Reading and Writing files task package function read SAS dataset haven read_sas() read csv dataset readr read_csv() read excel file readxl read_excel() read in multiple files rlocal read.all() write csv file readr write_csv() write excel file openxlsx write.xlsx() write object to Word/HTML/PDF arsenal write2word(), write2html(), write2pdf() write text to file base sink() print pretty markdown table knitr kable() Table 3.2: Manipulating data task package function summarize dataset summarytools dfSummary() create data from m, d, y arsenal mdy.Date() compare 2 datasets arsenal comparedf() transpose data tidyr gather() and spread() create categorical data from continuous base cut() X in (‘a’,‘b’,‘c’) base %in%, match() X NOT in (‘a’,‘b’,‘c’) arsenal %nin% concatenate strings base paste0() Table 3.3: Modeling and Statistical Tests task package function table 1, unpaired data arsenal tableby() table 1, paired data arsenal paired() correlations stats cor.test() partial correlations ppcor pcor.test() binomial CI rlocal cibinom() poisson CI survival cipoisson() t-tests stats t.test() Wilcoxon/Kolmogorov-Smirnov test stats wilcox.test(), ks.test() linear regression stats lm() logistic regression stats glm(, family=binomial) poisson regression stats glm( , family=poisson) negative binomial regression MASS glm.nb() cox regression survival coxph() quantile regression quantreg rq() robust regression MASS rlm() generalized additive regression gam gam() create table from multiple models arsenal modelsum() linear mixed effects (random slope) model nlme lme() person-years analysis survival pyears() incidence rates rlocal poprates() "]
]
